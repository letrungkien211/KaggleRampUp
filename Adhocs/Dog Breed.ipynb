{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trule/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, Input, AveragePooling2D, Lambda\n",
    "from urllib import request\n",
    "from keras.callbacks import TensorBoard\n",
    "import tempfile\n",
    "from keras import optimizers\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define \n",
    "root_dir = '../data/kaggle/dog-breed/'\n",
    "labels_path = os.path.join(root_dir, 'labels.csv')\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "test_dir = os.path.join(root_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start download!\n",
      "Start unzip\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def fetch_data():\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "        zip_path = os.path.join(tempfile.gettempdir(), 'dog-breed.zip')\n",
    "        print('Start download!')\n",
    "        request.urlretrieve('https://kienle.blob.core.windows.net/public/kaggle/dog-breed.zip', zip_path)\n",
    "        print('Start unzip')\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(root_dir)\n",
    "        with zipfile.ZipFile(os.path.join(root_dir,'test.zip'), 'r') as zip_ref:\n",
    "            zip_ref.extractall(root_dir)\n",
    "        with zipfile.ZipFile(os.path.join(root_dir,'train.zip'), 'r') as zip_ref:\n",
    "            zip_ref.extractall(root_dir)\n",
    "        os.remove(zip_path)\n",
    "        os.remove(os.path.join(root_dir,'train.zip'))\n",
    "        os.remove(os.path.join(root_dir,'test.zip'))\n",
    "        print('Done')\n",
    "fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv  sample_submission.csv  test  train\r\n"
     ]
    }
   ],
   "source": [
    "# Confirm all data are ready \n",
    "# Expected output: labels.csv  sample_submission.csv  test  train\n",
    "!ls $root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_images = pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10222 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_valid_generator = ImageDataGenerator().flow_from_dataframe(pd_images, train_dir, batch_size=32, x_col='id', y_col='breed', has_ext=False, target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_valid_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "class FeaturesExtractor():\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        model = vgg16.VGG16(include_top=False, input_shape=self.input_shape, weights='imagenet')\n",
    "        inputs = Input(self.input_shape)\n",
    "        x = inputs\n",
    "        x = Lambda(vgg16.preprocess_input, name='preprocessing')(x)\n",
    "        x = model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        model = Model(inputs, x)\n",
    "        self.model = model\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_features_extractor = FeaturesExtractor((224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(num_classes, input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    x = inputs\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 320/320 [01:04<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((train_valid_generator.n, 512))\n",
    "y_train = np.zeros((train_valid_generator.n, 120))\n",
    "for i in tqdm(range(len(train_valid_generator)), ncols=100):\n",
    "    temp_x, temp_y = train_valid_generator[i]\n",
    "    start_index = i*train_valid_generator.batch_size\n",
    "    X_train[start_index:start_index + temp_x.shape[0]] = vgg_features_extractor.predict(temp_x)\n",
    "    y_train[start_index:start_index + temp_x.shape[0]] = temp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_simple_model(num_classes, (512,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 61,560\n",
      "Trainable params: 61,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/100\n",
      "9199/9199 [==============================] - 0s 37us/step - loss: 14.8212 - acc: 0.0171 - val_loss: 12.5191 - val_acc: 0.0684\n",
      "Epoch 2/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 13.6392 - acc: 0.0528 - val_loss: 10.8400 - val_acc: 0.1378\n",
      "Epoch 3/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 12.4386 - acc: 0.0937 - val_loss: 9.2404 - val_acc: 0.1965\n",
      "Epoch 4/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 11.1605 - acc: 0.1435 - val_loss: 8.1093 - val_acc: 0.2796\n",
      "Epoch 5/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 10.1119 - acc: 0.1984 - val_loss: 7.3838 - val_acc: 0.3382\n",
      "Epoch 6/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 9.1445 - acc: 0.2434 - val_loss: 6.5510 - val_acc: 0.3783\n",
      "Epoch 7/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 8.3079 - acc: 0.2817 - val_loss: 5.9451 - val_acc: 0.4321\n",
      "Epoch 8/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 7.5722 - acc: 0.3255 - val_loss: 5.6419 - val_acc: 0.4457\n",
      "Epoch 9/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 7.0041 - acc: 0.3541 - val_loss: 5.0710 - val_acc: 0.4770\n",
      "Epoch 10/100\n",
      "9199/9199 [==============================] - 0s 11us/step - loss: 6.3623 - acc: 0.3924 - val_loss: 5.0006 - val_acc: 0.4848\n",
      "Epoch 11/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 6.0232 - acc: 0.4230 - val_loss: 4.6954 - val_acc: 0.5152\n",
      "Epoch 12/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 5.7134 - acc: 0.4382 - val_loss: 4.5021 - val_acc: 0.5298\n",
      "Epoch 13/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 5.4021 - acc: 0.4626 - val_loss: 4.2170 - val_acc: 0.5494\n",
      "Epoch 14/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 5.1021 - acc: 0.4802 - val_loss: 4.1429 - val_acc: 0.5484\n",
      "Epoch 15/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 4.8797 - acc: 0.4919 - val_loss: 3.8907 - val_acc: 0.5562\n",
      "Epoch 16/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 4.7101 - acc: 0.5083 - val_loss: 3.9176 - val_acc: 0.5699\n",
      "Epoch 17/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 4.5313 - acc: 0.5193 - val_loss: 3.8528 - val_acc: 0.5728\n",
      "Epoch 18/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 4.3946 - acc: 0.5293 - val_loss: 3.8170 - val_acc: 0.5797\n",
      "Epoch 19/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 4.2639 - acc: 0.5360 - val_loss: 3.8085 - val_acc: 0.5728\n",
      "Epoch 20/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 4.1026 - acc: 0.5513 - val_loss: 3.7586 - val_acc: 0.5748\n",
      "Epoch 21/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 4.0618 - acc: 0.5546 - val_loss: 3.7947 - val_acc: 0.5767\n",
      "Epoch 22/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.9866 - acc: 0.5657 - val_loss: 3.6831 - val_acc: 0.5855\n",
      "Epoch 23/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.8607 - acc: 0.5735 - val_loss: 3.5681 - val_acc: 0.5943\n",
      "Epoch 24/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.7641 - acc: 0.5742 - val_loss: 3.5385 - val_acc: 0.5865\n",
      "Epoch 25/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.6801 - acc: 0.5835 - val_loss: 3.5326 - val_acc: 0.5992\n",
      "Epoch 26/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.6110 - acc: 0.5953 - val_loss: 3.4684 - val_acc: 0.5943\n",
      "Epoch 27/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.6054 - acc: 0.5955 - val_loss: 3.4501 - val_acc: 0.5934\n",
      "Epoch 28/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.5210 - acc: 0.5957 - val_loss: 3.4319 - val_acc: 0.5982\n",
      "Epoch 29/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.3918 - acc: 0.6047 - val_loss: 3.3460 - val_acc: 0.6109\n",
      "Epoch 30/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.3515 - acc: 0.6076 - val_loss: 3.3413 - val_acc: 0.5992\n",
      "Epoch 31/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.2983 - acc: 0.6059 - val_loss: 3.3212 - val_acc: 0.6061\n",
      "Epoch 32/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.2786 - acc: 0.6071 - val_loss: 3.3146 - val_acc: 0.5875\n",
      "Epoch 33/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.1524 - acc: 0.6264 - val_loss: 3.2797 - val_acc: 0.6031\n",
      "Epoch 34/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.1806 - acc: 0.6177 - val_loss: 3.2092 - val_acc: 0.6080\n",
      "Epoch 35/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.1432 - acc: 0.6198 - val_loss: 3.2134 - val_acc: 0.5943\n",
      "Epoch 36/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.0302 - acc: 0.6292 - val_loss: 3.1943 - val_acc: 0.5992\n",
      "Epoch 37/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 3.0076 - acc: 0.6314 - val_loss: 3.2515 - val_acc: 0.6041\n",
      "Epoch 38/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.9909 - acc: 0.6318 - val_loss: 3.1733 - val_acc: 0.5982\n",
      "Epoch 39/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.9432 - acc: 0.6389 - val_loss: 3.1546 - val_acc: 0.6002\n",
      "Epoch 40/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.9600 - acc: 0.6342 - val_loss: 3.2426 - val_acc: 0.5924\n",
      "Epoch 41/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.8857 - acc: 0.6407 - val_loss: 3.1430 - val_acc: 0.5963\n",
      "Epoch 42/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.8483 - acc: 0.6453 - val_loss: 3.1879 - val_acc: 0.6002\n",
      "Epoch 43/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.8991 - acc: 0.6370 - val_loss: 3.1514 - val_acc: 0.6022\n",
      "Epoch 44/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.8285 - acc: 0.6485 - val_loss: 3.1677 - val_acc: 0.5963\n",
      "Epoch 45/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.8165 - acc: 0.6404 - val_loss: 3.1865 - val_acc: 0.6022\n",
      "Epoch 46/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.8283 - acc: 0.6418 - val_loss: 3.1477 - val_acc: 0.6070\n",
      "Epoch 47/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7682 - acc: 0.6527 - val_loss: 3.1045 - val_acc: 0.6158\n",
      "Epoch 48/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.8215 - acc: 0.6475 - val_loss: 3.1627 - val_acc: 0.6061\n",
      "Epoch 49/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7779 - acc: 0.6517 - val_loss: 3.1520 - val_acc: 0.6002\n",
      "Epoch 50/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7317 - acc: 0.6594 - val_loss: 3.1747 - val_acc: 0.6100\n",
      "Epoch 51/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7320 - acc: 0.6531 - val_loss: 3.1703 - val_acc: 0.5924\n",
      "Epoch 52/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7229 - acc: 0.6533 - val_loss: 3.1812 - val_acc: 0.6051\n",
      "Epoch 53/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6690 - acc: 0.6591 - val_loss: 3.1662 - val_acc: 0.5982\n",
      "Epoch 54/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6535 - acc: 0.6636 - val_loss: 3.1772 - val_acc: 0.6041\n",
      "Epoch 55/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7299 - acc: 0.6531 - val_loss: 3.1437 - val_acc: 0.6070\n",
      "Epoch 56/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7302 - acc: 0.6493 - val_loss: 3.2169 - val_acc: 0.5846\n",
      "Epoch 57/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7291 - acc: 0.6506 - val_loss: 3.1110 - val_acc: 0.6090\n",
      "Epoch 58/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6932 - acc: 0.6551 - val_loss: 3.1174 - val_acc: 0.6070\n",
      "Epoch 59/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6784 - acc: 0.6506 - val_loss: 3.1056 - val_acc: 0.6051\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6688 - acc: 0.6535 - val_loss: 3.1584 - val_acc: 0.5982\n",
      "Epoch 61/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6688 - acc: 0.6567 - val_loss: 3.0849 - val_acc: 0.6139\n",
      "Epoch 62/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6336 - acc: 0.6580 - val_loss: 3.1064 - val_acc: 0.6031\n",
      "Epoch 63/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.7029 - acc: 0.6520 - val_loss: 3.1347 - val_acc: 0.6041\n",
      "Epoch 64/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6709 - acc: 0.6575 - val_loss: 3.1190 - val_acc: 0.6061\n",
      "Epoch 65/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6404 - acc: 0.6572 - val_loss: 3.0690 - val_acc: 0.6051\n",
      "Epoch 66/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5868 - acc: 0.6719 - val_loss: 3.0662 - val_acc: 0.6080\n",
      "Epoch 67/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6561 - acc: 0.6568 - val_loss: 3.0780 - val_acc: 0.6080\n",
      "Epoch 68/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6322 - acc: 0.6620 - val_loss: 3.1262 - val_acc: 0.5904\n",
      "Epoch 69/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6069 - acc: 0.6616 - val_loss: 3.0797 - val_acc: 0.6090\n",
      "Epoch 70/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6204 - acc: 0.6570 - val_loss: 3.1313 - val_acc: 0.5963\n",
      "Epoch 71/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6425 - acc: 0.6563 - val_loss: 3.1210 - val_acc: 0.6051\n",
      "Epoch 72/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6094 - acc: 0.6638 - val_loss: 3.1489 - val_acc: 0.5914\n",
      "Epoch 73/100\n",
      "9199/9199 [==============================] - 0s 11us/step - loss: 2.6582 - acc: 0.6606 - val_loss: 3.1317 - val_acc: 0.6090\n",
      "Epoch 74/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6049 - acc: 0.6639 - val_loss: 3.0530 - val_acc: 0.6129\n",
      "Epoch 75/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6232 - acc: 0.6593 - val_loss: 3.1052 - val_acc: 0.5973\n",
      "Epoch 76/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5763 - acc: 0.6687 - val_loss: 3.1734 - val_acc: 0.6002\n",
      "Epoch 77/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5922 - acc: 0.6572 - val_loss: 3.1633 - val_acc: 0.6002\n",
      "Epoch 78/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6034 - acc: 0.6554 - val_loss: 3.1418 - val_acc: 0.5953\n",
      "Epoch 79/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6114 - acc: 0.6659 - val_loss: 3.1481 - val_acc: 0.5934\n",
      "Epoch 80/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5947 - acc: 0.6601 - val_loss: 3.1307 - val_acc: 0.6022\n",
      "Epoch 81/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5789 - acc: 0.6681 - val_loss: 3.1303 - val_acc: 0.5943\n",
      "Epoch 82/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5758 - acc: 0.6647 - val_loss: 3.1008 - val_acc: 0.6061\n",
      "Epoch 83/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5764 - acc: 0.6617 - val_loss: 3.1410 - val_acc: 0.5943\n",
      "Epoch 84/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.6047 - acc: 0.6611 - val_loss: 3.1637 - val_acc: 0.5953\n",
      "Epoch 85/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5608 - acc: 0.6658 - val_loss: 3.0946 - val_acc: 0.6061\n",
      "Epoch 86/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5847 - acc: 0.6636 - val_loss: 3.1265 - val_acc: 0.5894\n",
      "Epoch 87/100\n",
      "9199/9199 [==============================] - 0s 11us/step - loss: 2.5796 - acc: 0.6622 - val_loss: 3.1192 - val_acc: 0.5953\n",
      "Epoch 88/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5741 - acc: 0.6651 - val_loss: 3.0891 - val_acc: 0.6197\n",
      "Epoch 89/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5743 - acc: 0.6669 - val_loss: 3.0908 - val_acc: 0.6031\n",
      "Epoch 90/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5598 - acc: 0.6607 - val_loss: 3.0496 - val_acc: 0.6012\n",
      "Epoch 91/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5363 - acc: 0.6645 - val_loss: 3.0693 - val_acc: 0.5914\n",
      "Epoch 92/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5380 - acc: 0.6572 - val_loss: 2.9880 - val_acc: 0.6119\n",
      "Epoch 93/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5322 - acc: 0.6634 - val_loss: 2.9988 - val_acc: 0.6070\n",
      "Epoch 94/100\n",
      "9199/9199 [==============================] - 0s 11us/step - loss: 2.5217 - acc: 0.6653 - val_loss: 3.0602 - val_acc: 0.5904\n",
      "Epoch 95/100\n",
      "9199/9199 [==============================] - 0s 12us/step - loss: 2.5356 - acc: 0.6584 - val_loss: 3.0648 - val_acc: 0.5953\n",
      "Epoch 96/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5137 - acc: 0.6659 - val_loss: 3.0801 - val_acc: 0.5982\n",
      "Epoch 97/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.4853 - acc: 0.6707 - val_loss: 3.0217 - val_acc: 0.5973\n",
      "Epoch 98/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.4927 - acc: 0.6668 - val_loss: 3.0602 - val_acc: 0.5846\n",
      "Epoch 99/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5052 - acc: 0.6666 - val_loss: 3.0419 - val_acc: 0.5973\n",
      "Epoch 100/100\n",
      "9199/9199 [==============================] - 0s 10us/step - loss: 2.5169 - acc: 0.6574 - val_loss: 3.0137 - val_acc: 0.5973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8402b3b38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=100, callbacks=[TensorBoard('./data/logs/run7/')], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
