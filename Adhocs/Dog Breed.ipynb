{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, Input, AveragePooling2D, Lambda\n",
    "from urllib import request\n",
    "from keras.callbacks import TensorBoard\n",
    "import tempfile\n",
    "from keras import optimizers\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from keras.applications import vgg16, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on kaggle kernel: True\n"
     ]
    }
   ],
   "source": [
    "NOT_KAGGLE_KERNEL = os.environ.get('NOT_KAGGLE_KERNEL', 'false') == 'true'\n",
    "print('Run on kaggle kernel:', NOT_KAGGLE_KERNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../input/dog-breed' if NOT_KAGGLE_KERNEL else '../input'\n",
    "EPOCHS = 100\n",
    "IMAGE_SIZE = (224,224)\n",
    "INPUT_SHAPE = IMAGE_SIZE + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        os.makedirs(ROOT_DIR)\n",
    "        zip_path = os.path.join(tempfile.gettempdir(), 'dog-breed.zip')\n",
    "        print('Start download!')\n",
    "        request.urlretrieve('https://kienle.blob.core.windows.net/public/kaggle/dog-breed.zip', zip_path)\n",
    "        print('Start unzip')\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(ROOT_DIR)\n",
    "        with zipfile.ZipFile(os.path.join(ROOT_DIR,'test.zip'), 'r') as zip_ref:\n",
    "            zip_ref.extractall(ROOT_DIR)\n",
    "        with zipfile.ZipFile(os.path.join(ROOT_DIR,'train.zip'), 'r') as zip_ref:\n",
    "            zip_ref.extractall(ROOT_DIR)\n",
    "        os.remove(zip_path)\n",
    "        os.remove(os.path.join(ROOT_DIR,'train.zip'))\n",
    "        os.remove(os.path.join(ROOT_DIR,'test.zip'))\n",
    "        print('Done')\n",
    "if(NOT_KAGGLE_KERNEL):\n",
    "    fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Confirm all data are ready \n",
    "# Expected output: labels.csv  sample_submission.csv  test  train\n",
    "!ls $ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_images = pd.read_csv(os.path.join(ROOT_DIR, 'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10222 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_valid_generator = ImageDataGenerator().flow_from_dataframe(pd_images, os.path.join(ROOT_DIR, 'train'), batch_size=32, x_col='id', y_col='breed', has_ext=False, target_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_valid_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtractor():\n",
    "    def __init__(self, input_shape, pretrained_model, preprocess_input):\n",
    "        self.input_shape = input_shape\n",
    "        model = pretrained_model(include_top=False, input_shape=self.input_shape, weights='imagenet')\n",
    "        inputs = Input(self.input_shape)\n",
    "        x = inputs\n",
    "        x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "        x = model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        model = Model(inputs, x)\n",
    "        self.model = model\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trule\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "vgg_features_extractor = FeaturesExtractor(INPUT_SHAPE, vgg16.VGG16, vgg16.preprocess_input)\n",
    "resnet50_features_extractor = FeaturesExtractor(INPUT_SHAPE, resnet50.ResNet50, resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(num_classes, input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    x = inputs\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 320/320 [00:43<00:00,  7.42it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((train_valid_generator.n,) + INPUT_SHAPE)\n",
    "y_train = np.zeros((train_valid_generator.n, 120))\n",
    "for i in tqdm(range(len(train_valid_generator)), ncols=100):\n",
    "    temp_x, temp_y = train_valid_generator[i]\n",
    "    start_index = i*train_valid_generator.batch_size\n",
    "    X_train[start_index:start_index + temp_x.shape[0]] = temp_x\n",
    "    y_train[start_index:start_index + temp_x.shape[0]] = temp_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate vgg features\n",
    "vgg_features = vgg_features_extractor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 61,560\n",
      "Trainable params: 61,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_based_model = create_simple_model(num_classes, vgg_features_extractor.model.output.get_shape().as_list()[1:])\n",
    "vgg_based_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "if NOT_KAGGLE_KERNEL:\n",
    "    callbacks = [TensorBoard('./data/logs/vgg-{0}'.format(datetime.now().isoformat().replace(':','-')))]\n",
    "else:\n",
    "    callbacks = []\n",
    "    \n",
    "vgg_based_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/100\n",
      "9199/9199 [==============================] - ETA: 14s - loss: 15.1680 - acc: 0.011 - ETA: 1s - loss: 15.0745 - acc: 0.013 - ETA: 0s - loss: 14.9673 - acc: 0.01 - ETA: 0s - loss: 14.8332 - acc: 0.01 - 1s 82us/step - loss: 14.7462 - acc: 0.0208 - val_loss: 12.4536 - val_acc: 0.0655\n",
      "Epoch 2/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 14.1425 - acc: 0.03 - ETA: 0s - loss: 14.1213 - acc: 0.03 - ETA: 0s - loss: 13.9854 - acc: 0.04 - ETA: 0s - loss: 13.8337 - acc: 0.04 - 0s 21us/step - loss: 13.7303 - acc: 0.0498 - val_loss: 10.6226 - val_acc: 0.1476\n",
      "Epoch 3/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 12.7442 - acc: 0.07 - ETA: 0s - loss: 12.7943 - acc: 0.08 - ETA: 0s - loss: 12.4917 - acc: 0.09 - ETA: 0s - loss: 12.3515 - acc: 0.09 - 0s 20us/step - loss: 12.3414 - acc: 0.0994 - val_loss: 8.9972 - val_acc: 0.2317\n",
      "Epoch 4/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 10.5868 - acc: 0.16 - ETA: 0s - loss: 11.3968 - acc: 0.13 - ETA: 0s - loss: 11.2915 - acc: 0.13 - 0s 18us/step - loss: 11.0658 - acc: 0.1444 - val_loss: 7.4488 - val_acc: 0.3050\n",
      "Epoch 5/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 10.1305 - acc: 0.14 - ETA: 0s - loss: 10.0712 - acc: 0.18 - ETA: 0s - loss: 9.9075 - acc: 0.1956 - 0s 18us/step - loss: 9.7790 - acc: 0.2037 - val_loss: 6.5191 - val_acc: 0.3724\n",
      "Epoch 6/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 9.2783 - acc: 0.191 - ETA: 0s - loss: 8.9192 - acc: 0.241 - ETA: 0s - loss: 8.7776 - acc: 0.244 - ETA: 0s - loss: 8.6874 - acc: 0.251 - 0s 19us/step - loss: 8.6782 - acc: 0.2530 - val_loss: 5.7504 - val_acc: 0.4282\n",
      "Epoch 7/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 7.8059 - acc: 0.300 - ETA: 0s - loss: 8.0326 - acc: 0.287 - ETA: 0s - loss: 7.9345 - acc: 0.290 - 0s 18us/step - loss: 7.8251 - acc: 0.2997 - val_loss: 5.2681 - val_acc: 0.4594\n",
      "Epoch 8/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 6.9594 - acc: 0.312 - ETA: 0s - loss: 7.4188 - acc: 0.318 - ETA: 0s - loss: 7.2308 - acc: 0.334 - ETA: 0s - loss: 7.1778 - acc: 0.338 - 0s 19us/step - loss: 7.1663 - acc: 0.3380 - val_loss: 4.7760 - val_acc: 0.4888\n",
      "Epoch 9/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 7.0566 - acc: 0.351 - ETA: 0s - loss: 6.5806 - acc: 0.372 - ETA: 0s - loss: 6.5151 - acc: 0.377 - ETA: 0s - loss: 6.4908 - acc: 0.374 - 0s 20us/step - loss: 6.4881 - acc: 0.3749 - val_loss: 4.3361 - val_acc: 0.4976\n",
      "Epoch 10/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 5.8869 - acc: 0.382 - ETA: 0s - loss: 6.0663 - acc: 0.398 - ETA: 0s - loss: 6.0960 - acc: 0.395 - 0s 18us/step - loss: 6.0509 - acc: 0.3983 - val_loss: 3.9449 - val_acc: 0.5435\n",
      "Epoch 11/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 5.8088 - acc: 0.433 - ETA: 0s - loss: 5.5911 - acc: 0.420 - ETA: 0s - loss: 5.4550 - acc: 0.430 - 0s 18us/step - loss: 5.3847 - acc: 0.4352 - val_loss: 3.7691 - val_acc: 0.5474\n",
      "Epoch 12/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 5.4913 - acc: 0.410 - ETA: 0s - loss: 5.0519 - acc: 0.451 - ETA: 0s - loss: 5.0270 - acc: 0.456 - 0s 18us/step - loss: 5.0860 - acc: 0.4552 - val_loss: 3.6405 - val_acc: 0.5670\n",
      "Epoch 13/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.6190 - acc: 0.449 - ETA: 0s - loss: 4.7545 - acc: 0.488 - ETA: 0s - loss: 4.6745 - acc: 0.494 - 0s 19us/step - loss: 4.7185 - acc: 0.4895 - val_loss: 3.5371 - val_acc: 0.5855\n",
      "Epoch 14/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.2880 - acc: 0.507 - ETA: 0s - loss: 4.4239 - acc: 0.500 - ETA: 0s - loss: 4.4213 - acc: 0.501 - ETA: 0s - loss: 4.4852 - acc: 0.499 - 0s 22us/step - loss: 4.5284 - acc: 0.4976 - val_loss: 3.4936 - val_acc: 0.5787\n",
      "Epoch 15/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.6348 - acc: 0.496 - ETA: 0s - loss: 4.4984 - acc: 0.497 - ETA: 0s - loss: 4.4266 - acc: 0.500 - ETA: 0s - loss: 4.3352 - acc: 0.506 - 0s 19us/step - loss: 4.3287 - acc: 0.5072 - val_loss: 3.3492 - val_acc: 0.5855\n",
      "Epoch 16/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.1277 - acc: 0.496 - ETA: 0s - loss: 4.0787 - acc: 0.534 - ETA: 0s - loss: 4.0471 - acc: 0.534 - ETA: 0s - loss: 4.0869 - acc: 0.533 - 0s 20us/step - loss: 4.1074 - acc: 0.5308 - val_loss: 3.3316 - val_acc: 0.5904\n",
      "Epoch 17/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.8763 - acc: 0.554 - ETA: 0s - loss: 3.9169 - acc: 0.552 - ETA: 0s - loss: 3.9732 - acc: 0.545 - ETA: 0s - loss: 3.9379 - acc: 0.544 - 0s 20us/step - loss: 3.9454 - acc: 0.5435 - val_loss: 3.2828 - val_acc: 0.5894\n",
      "Epoch 18/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.6217 - acc: 0.566 - ETA: 0s - loss: 3.8522 - acc: 0.543 - ETA: 0s - loss: 3.8643 - acc: 0.543 - ETA: 0s - loss: 3.8323 - acc: 0.546 - 0s 20us/step - loss: 3.8460 - acc: 0.5459 - val_loss: 3.1813 - val_acc: 0.5924\n",
      "Epoch 19/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.9455 - acc: 0.539 - ETA: 0s - loss: 3.7573 - acc: 0.551 - ETA: 0s - loss: 3.6535 - acc: 0.567 - ETA: 0s - loss: 3.6796 - acc: 0.558 - 0s 22us/step - loss: 3.7192 - acc: 0.5580 - val_loss: 3.1837 - val_acc: 0.6022\n",
      "Epoch 20/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.5344 - acc: 0.605 - ETA: 0s - loss: 3.5955 - acc: 0.570 - ETA: 0s - loss: 3.6066 - acc: 0.570 - ETA: 0s - loss: 3.5646 - acc: 0.572 - 0s 21us/step - loss: 3.5468 - acc: 0.5734 - val_loss: 3.1500 - val_acc: 0.5982\n",
      "Epoch 21/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.5603 - acc: 0.566 - ETA: 0s - loss: 3.4296 - acc: 0.585 - ETA: 0s - loss: 3.4633 - acc: 0.588 - ETA: 0s - loss: 3.4226 - acc: 0.588 - 0s 21us/step - loss: 3.4137 - acc: 0.5883 - val_loss: 3.1935 - val_acc: 0.5953\n",
      "Epoch 22/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.2087 - acc: 0.578 - ETA: 0s - loss: 3.4890 - acc: 0.568 - ETA: 0s - loss: 3.4126 - acc: 0.576 - ETA: 0s - loss: 3.3985 - acc: 0.578 - 0s 22us/step - loss: 3.3733 - acc: 0.5813 - val_loss: 3.1107 - val_acc: 0.6022\n",
      "Epoch 23/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.1071 - acc: 0.644 - ETA: 0s - loss: 3.0545 - acc: 0.603 - ETA: 0s - loss: 3.2101 - acc: 0.596 - ETA: 0s - loss: 3.1880 - acc: 0.597 - 0s 22us/step - loss: 3.2155 - acc: 0.5973 - val_loss: 3.0831 - val_acc: 0.5982\n",
      "Epoch 24/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.0355 - acc: 0.585 - ETA: 0s - loss: 3.0779 - acc: 0.603 - ETA: 0s - loss: 3.1672 - acc: 0.602 - ETA: 0s - loss: 3.1451 - acc: 0.601 - 0s 21us/step - loss: 3.1699 - acc: 0.5997 - val_loss: 3.0182 - val_acc: 0.6158\n",
      "Epoch 25/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.5430 - acc: 0.644 - ETA: 0s - loss: 3.0352 - acc: 0.614 - ETA: 0s - loss: 3.0320 - acc: 0.611 - ETA: 0s - loss: 3.0739 - acc: 0.608 - 0s 20us/step - loss: 3.0702 - acc: 0.6076 - val_loss: 2.9032 - val_acc: 0.6158\n",
      "Epoch 26/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.0370 - acc: 0.566 - ETA: 0s - loss: 2.8476 - acc: 0.620 - ETA: 0s - loss: 2.9825 - acc: 0.608 - ETA: 0s - loss: 2.9754 - acc: 0.611 - 0s 19us/step - loss: 2.9821 - acc: 0.6110 - val_loss: 2.9594 - val_acc: 0.6149\n",
      "Epoch 27/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.0692 - acc: 0.601 - ETA: 0s - loss: 3.0082 - acc: 0.612 - ETA: 0s - loss: 2.9783 - acc: 0.615 - 0s 18us/step - loss: 2.9590 - acc: 0.6179 - val_loss: 2.8974 - val_acc: 0.6266\n",
      "Epoch 28/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.7581 - acc: 0.636 - ETA: 0s - loss: 2.8235 - acc: 0.630 - ETA: 0s - loss: 2.8323 - acc: 0.621 - 0s 18us/step - loss: 2.8840 - acc: 0.6157 - val_loss: 2.8493 - val_acc: 0.6237\n",
      "Epoch 29/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.6137 - acc: 0.652 - ETA: 0s - loss: 2.8212 - acc: 0.627 - ETA: 0s - loss: 2.8023 - acc: 0.628 - 0s 18us/step - loss: 2.7480 - acc: 0.6331 - val_loss: 2.7678 - val_acc: 0.6207\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - ETA: 0s - loss: 2.6980 - acc: 0.652 - ETA: 0s - loss: 2.7642 - acc: 0.631 - ETA: 0s - loss: 2.7082 - acc: 0.633 - ETA: 0s - loss: 2.7267 - acc: 0.635 - 0s 19us/step - loss: 2.7273 - acc: 0.6346 - val_loss: 2.8446 - val_acc: 0.6022\n",
      "Epoch 31/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2740 - acc: 0.664 - ETA: 0s - loss: 2.6458 - acc: 0.629 - ETA: 0s - loss: 2.6227 - acc: 0.635 - 0s 18us/step - loss: 2.6836 - acc: 0.6340 - val_loss: 2.7049 - val_acc: 0.6364\n",
      "Epoch 32/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3172 - acc: 0.691 - ETA: 0s - loss: 2.6288 - acc: 0.639 - ETA: 0s - loss: 2.6561 - acc: 0.636 - 0s 17us/step - loss: 2.6814 - acc: 0.6377 - val_loss: 2.7499 - val_acc: 0.6266\n",
      "Epoch 33/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.5859 - acc: 0.664 - ETA: 0s - loss: 2.7324 - acc: 0.633 - ETA: 0s - loss: 2.5601 - acc: 0.649 - ETA: 0s - loss: 2.5749 - acc: 0.647 - 0s 24us/step - loss: 2.6472 - acc: 0.6385 - val_loss: 2.7748 - val_acc: 0.6237\n",
      "Epoch 34/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.5298 - acc: 0.632 - ETA: 0s - loss: 2.4952 - acc: 0.657 - ETA: 0s - loss: 2.5651 - acc: 0.646 - ETA: 0s - loss: 2.5746 - acc: 0.647 - 0s 24us/step - loss: 2.5593 - acc: 0.6475 - val_loss: 2.7249 - val_acc: 0.6276\n",
      "Epoch 35/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.3788 - acc: 0.585 - ETA: 0s - loss: 2.5397 - acc: 0.642 - ETA: 0s - loss: 2.5759 - acc: 0.643 - ETA: 0s - loss: 2.5805 - acc: 0.642 - 0s 20us/step - loss: 2.5988 - acc: 0.6399 - val_loss: 2.6898 - val_acc: 0.6285\n",
      "Epoch 36/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3073 - acc: 0.675 - ETA: 0s - loss: 2.4689 - acc: 0.653 - ETA: 0s - loss: 2.4420 - acc: 0.658 - ETA: 0s - loss: 2.4468 - acc: 0.658 - 0s 22us/step - loss: 2.4723 - acc: 0.6552 - val_loss: 2.7275 - val_acc: 0.6227\n",
      "Epoch 37/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.4436 - acc: 0.699 - ETA: 0s - loss: 2.3956 - acc: 0.656 - ETA: 0s - loss: 2.4672 - acc: 0.645 - ETA: 0s - loss: 2.4471 - acc: 0.652 - 0s 21us/step - loss: 2.4840 - acc: 0.6491 - val_loss: 2.6998 - val_acc: 0.6276\n",
      "Epoch 38/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0121 - acc: 0.691 - ETA: 0s - loss: 2.5020 - acc: 0.649 - ETA: 0s - loss: 2.4117 - acc: 0.657 - 0s 18us/step - loss: 2.4263 - acc: 0.6604 - val_loss: 2.7121 - val_acc: 0.6207\n",
      "Epoch 39/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1592 - acc: 0.718 - ETA: 0s - loss: 2.3357 - acc: 0.666 - ETA: 0s - loss: 2.3684 - acc: 0.669 - ETA: 0s - loss: 2.4264 - acc: 0.662 - 0s 21us/step - loss: 2.4427 - acc: 0.6613 - val_loss: 2.7011 - val_acc: 0.6276\n",
      "Epoch 40/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2315 - acc: 0.687 - ETA: 0s - loss: 2.3904 - acc: 0.665 - ETA: 0s - loss: 2.4157 - acc: 0.656 - ETA: 0s - loss: 2.4190 - acc: 0.657 - 0s 21us/step - loss: 2.4225 - acc: 0.6579 - val_loss: 2.6775 - val_acc: 0.6285\n",
      "Epoch 41/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5784 - acc: 0.718 - ETA: 0s - loss: 2.3196 - acc: 0.668 - ETA: 0s - loss: 2.3609 - acc: 0.661 - 0s 18us/step - loss: 2.3985 - acc: 0.6611 - val_loss: 2.6785 - val_acc: 0.6442\n",
      "Epoch 42/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.9152 - acc: 0.589 - ETA: 0s - loss: 2.4686 - acc: 0.641 - ETA: 0s - loss: 2.3732 - acc: 0.652 - ETA: 0s - loss: 2.3866 - acc: 0.653 - 0s 19us/step - loss: 2.3973 - acc: 0.6531 - val_loss: 2.7254 - val_acc: 0.6237\n",
      "Epoch 43/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3234 - acc: 0.664 - ETA: 0s - loss: 2.4246 - acc: 0.662 - ETA: 0s - loss: 2.3391 - acc: 0.670 - 0s 18us/step - loss: 2.3814 - acc: 0.6654 - val_loss: 2.6738 - val_acc: 0.6266\n",
      "Epoch 44/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3369 - acc: 0.668 - ETA: 0s - loss: 2.3928 - acc: 0.660 - ETA: 0s - loss: 2.3415 - acc: 0.659 - ETA: 0s - loss: 2.3159 - acc: 0.661 - 0s 19us/step - loss: 2.3156 - acc: 0.6621 - val_loss: 2.5777 - val_acc: 0.6217\n",
      "Epoch 45/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2726 - acc: 0.660 - ETA: 0s - loss: 2.1826 - acc: 0.677 - ETA: 0s - loss: 2.2510 - acc: 0.663 - ETA: 0s - loss: 2.2602 - acc: 0.663 - 0s 19us/step - loss: 2.2734 - acc: 0.6624 - val_loss: 2.6032 - val_acc: 0.6354\n",
      "Epoch 46/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2933 - acc: 0.671 - ETA: 0s - loss: 2.3343 - acc: 0.662 - ETA: 0s - loss: 2.2613 - acc: 0.666 - ETA: 0s - loss: 2.2545 - acc: 0.669 - 0s 19us/step - loss: 2.2641 - acc: 0.6684 - val_loss: 2.5937 - val_acc: 0.6334\n",
      "Epoch 47/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3669 - acc: 0.656 - ETA: 0s - loss: 2.1818 - acc: 0.669 - ETA: 0s - loss: 2.2588 - acc: 0.661 - 0s 18us/step - loss: 2.2496 - acc: 0.6663 - val_loss: 2.5929 - val_acc: 0.6315\n",
      "Epoch 48/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1064 - acc: 0.687 - ETA: 0s - loss: 2.1753 - acc: 0.674 - ETA: 0s - loss: 2.1945 - acc: 0.681 - 0s 18us/step - loss: 2.1777 - acc: 0.6776 - val_loss: 2.6007 - val_acc: 0.6334\n",
      "Epoch 49/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9234 - acc: 0.707 - ETA: 0s - loss: 2.2466 - acc: 0.668 - ETA: 0s - loss: 2.2319 - acc: 0.669 - 0s 18us/step - loss: 2.2258 - acc: 0.6684 - val_loss: 2.5578 - val_acc: 0.6227\n",
      "Epoch 50/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7481 - acc: 0.734 - ETA: 0s - loss: 2.0502 - acc: 0.686 - ETA: 0s - loss: 2.1498 - acc: 0.673 - ETA: 0s - loss: 2.1702 - acc: 0.670 - 0s 19us/step - loss: 2.1658 - acc: 0.6712 - val_loss: 2.5458 - val_acc: 0.6325\n",
      "Epoch 51/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1857 - acc: 0.664 - ETA: 0s - loss: 2.0657 - acc: 0.677 - ETA: 0s - loss: 2.1305 - acc: 0.674 - ETA: 0s - loss: 2.1458 - acc: 0.672 - 0s 19us/step - loss: 2.1389 - acc: 0.6729 - val_loss: 2.5233 - val_acc: 0.6276\n",
      "Epoch 52/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6954 - acc: 0.718 - ETA: 0s - loss: 2.2225 - acc: 0.668 - ETA: 0s - loss: 2.1628 - acc: 0.676 - ETA: 0s - loss: 2.1605 - acc: 0.671 - 0s 19us/step - loss: 2.1611 - acc: 0.6715 - val_loss: 2.4683 - val_acc: 0.6413\n",
      "Epoch 53/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.6602 - acc: 0.648 - ETA: 0s - loss: 2.1112 - acc: 0.676 - ETA: 0s - loss: 2.1459 - acc: 0.675 - ETA: 0s - loss: 2.1120 - acc: 0.679 - 0s 19us/step - loss: 2.1030 - acc: 0.6809 - val_loss: 2.5129 - val_acc: 0.6315\n",
      "Epoch 54/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7694 - acc: 0.734 - ETA: 0s - loss: 2.1091 - acc: 0.688 - ETA: 0s - loss: 2.0817 - acc: 0.688 - ETA: 0s - loss: 2.1319 - acc: 0.679 - 0s 19us/step - loss: 2.1305 - acc: 0.6794 - val_loss: 2.4733 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2881 - acc: 0.664 - ETA: 0s - loss: 2.1237 - acc: 0.676 - ETA: 0s - loss: 2.1049 - acc: 0.677 - ETA: 0s - loss: 2.0827 - acc: 0.679 - 0s 19us/step - loss: 2.0970 - acc: 0.6769 - val_loss: 2.4550 - val_acc: 0.6393\n",
      "Epoch 56/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.4843 - acc: 0.668 - ETA: 0s - loss: 2.0447 - acc: 0.684 - ETA: 0s - loss: 2.0709 - acc: 0.677 - 0s 18us/step - loss: 2.0940 - acc: 0.6765 - val_loss: 2.5220 - val_acc: 0.6422\n",
      "Epoch 57/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3603 - acc: 0.644 - ETA: 0s - loss: 2.0708 - acc: 0.685 - ETA: 0s - loss: 2.0500 - acc: 0.685 - 0s 18us/step - loss: 2.0667 - acc: 0.6840 - val_loss: 2.4595 - val_acc: 0.6315\n",
      "Epoch 58/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0742 - acc: 0.675 - ETA: 0s - loss: 2.0627 - acc: 0.681 - ETA: 0s - loss: 2.0905 - acc: 0.682 - 0s 18us/step - loss: 2.0848 - acc: 0.6796 - val_loss: 2.4888 - val_acc: 0.6403\n",
      "Epoch 59/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3718 - acc: 0.632 - ETA: 0s - loss: 2.1053 - acc: 0.668 - ETA: 0s - loss: 2.0772 - acc: 0.672 - 0s 18us/step - loss: 2.0633 - acc: 0.6738 - val_loss: 2.4344 - val_acc: 0.6422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0693 - acc: 0.718 - ETA: 0s - loss: 2.0286 - acc: 0.686 - ETA: 0s - loss: 1.9939 - acc: 0.682 - ETA: 0s - loss: 2.0304 - acc: 0.679 - 0s 20us/step - loss: 2.0396 - acc: 0.6787 - val_loss: 2.4781 - val_acc: 0.6305\n",
      "Epoch 61/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8783 - acc: 0.668 - ETA: 0s - loss: 2.0478 - acc: 0.689 - ETA: 0s - loss: 2.0504 - acc: 0.686 - 0s 18us/step - loss: 2.0456 - acc: 0.6834 - val_loss: 2.4824 - val_acc: 0.6383\n",
      "Epoch 62/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1971 - acc: 0.722 - ETA: 0s - loss: 1.9834 - acc: 0.703 - ETA: 0s - loss: 2.0220 - acc: 0.691 - 0s 18us/step - loss: 2.0396 - acc: 0.6874 - val_loss: 2.4781 - val_acc: 0.6325\n",
      "Epoch 63/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0520 - acc: 0.691 - ETA: 0s - loss: 1.9874 - acc: 0.685 - ETA: 0s - loss: 2.0215 - acc: 0.685 - ETA: 0s - loss: 2.0154 - acc: 0.683 - 0s 19us/step - loss: 2.0092 - acc: 0.6838 - val_loss: 2.4588 - val_acc: 0.6373\n",
      "Epoch 64/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8674 - acc: 0.652 - ETA: 0s - loss: 1.9442 - acc: 0.682 - ETA: 0s - loss: 1.9992 - acc: 0.675 - 0s 18us/step - loss: 2.0443 - acc: 0.6739 - val_loss: 2.4799 - val_acc: 0.6276\n",
      "Epoch 65/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9324 - acc: 0.644 - ETA: 0s - loss: 1.9387 - acc: 0.691 - ETA: 0s - loss: 1.9562 - acc: 0.690 - 0s 18us/step - loss: 2.0086 - acc: 0.6851 - val_loss: 2.4461 - val_acc: 0.6256\n",
      "Epoch 66/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1368 - acc: 0.636 - ETA: 0s - loss: 1.9433 - acc: 0.687 - ETA: 0s - loss: 1.9818 - acc: 0.690 - ETA: 0s - loss: 2.0086 - acc: 0.685 - 0s 20us/step - loss: 1.9873 - acc: 0.6874 - val_loss: 2.4539 - val_acc: 0.6354\n",
      "Epoch 67/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6586 - acc: 0.703 - ETA: 0s - loss: 2.0095 - acc: 0.674 - ETA: 0s - loss: 2.0645 - acc: 0.670 - 0s 18us/step - loss: 2.0474 - acc: 0.6743 - val_loss: 2.4837 - val_acc: 0.6197\n",
      "Epoch 68/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7635 - acc: 0.691 - ETA: 0s - loss: 1.9007 - acc: 0.691 - ETA: 0s - loss: 1.9136 - acc: 0.695 - 0s 18us/step - loss: 1.9593 - acc: 0.6869 - val_loss: 2.3389 - val_acc: 0.6383\n",
      "Epoch 69/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7474 - acc: 0.687 - ETA: 0s - loss: 1.9429 - acc: 0.698 - ETA: 0s - loss: 1.9497 - acc: 0.687 - 0s 18us/step - loss: 1.9469 - acc: 0.6852 - val_loss: 2.2794 - val_acc: 0.6364\n",
      "Epoch 70/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7709 - acc: 0.699 - ETA: 0s - loss: 1.8769 - acc: 0.696 - ETA: 0s - loss: 1.9467 - acc: 0.690 - 0s 18us/step - loss: 1.9627 - acc: 0.6857 - val_loss: 2.3491 - val_acc: 0.6364\n",
      "Epoch 71/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8693 - acc: 0.695 - ETA: 0s - loss: 1.9889 - acc: 0.685 - ETA: 0s - loss: 1.9449 - acc: 0.687 - 0s 18us/step - loss: 1.9423 - acc: 0.6853 - val_loss: 2.3086 - val_acc: 0.6471\n",
      "Epoch 72/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8620 - acc: 0.718 - ETA: 0s - loss: 1.9236 - acc: 0.681 - ETA: 0s - loss: 1.9177 - acc: 0.682 - ETA: 0s - loss: 1.9274 - acc: 0.683 - 0s 19us/step - loss: 1.9290 - acc: 0.6841 - val_loss: 2.3698 - val_acc: 0.6364\n",
      "Epoch 73/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7266 - acc: 0.687 - ETA: 0s - loss: 1.8222 - acc: 0.699 - ETA: 0s - loss: 1.8383 - acc: 0.694 - 0s 18us/step - loss: 1.8896 - acc: 0.6912 - val_loss: 2.3447 - val_acc: 0.6325\n",
      "Epoch 74/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8404 - acc: 0.710 - ETA: 0s - loss: 1.9273 - acc: 0.685 - ETA: 0s - loss: 1.9001 - acc: 0.694 - 0s 18us/step - loss: 1.9009 - acc: 0.6900 - val_loss: 2.3405 - val_acc: 0.6403\n",
      "Epoch 75/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7961 - acc: 0.699 - ETA: 0s - loss: 1.9002 - acc: 0.690 - ETA: 0s - loss: 1.9076 - acc: 0.691 - 0s 18us/step - loss: 1.9179 - acc: 0.6896 - val_loss: 2.2809 - val_acc: 0.6344\n",
      "Epoch 76/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8968 - acc: 0.683 - ETA: 0s - loss: 1.8885 - acc: 0.695 - ETA: 0s - loss: 1.8984 - acc: 0.692 - 0s 18us/step - loss: 1.9066 - acc: 0.6867 - val_loss: 2.2952 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6052 - acc: 0.730 - ETA: 0s - loss: 1.8471 - acc: 0.697 - ETA: 0s - loss: 1.8625 - acc: 0.694 - ETA: 0s - loss: 1.8639 - acc: 0.694 - 0s 19us/step - loss: 1.8787 - acc: 0.6936 - val_loss: 2.3121 - val_acc: 0.6393\n",
      "Epoch 78/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6099 - acc: 0.726 - ETA: 0s - loss: 1.8093 - acc: 0.695 - ETA: 0s - loss: 1.9068 - acc: 0.693 - ETA: 0s - loss: 1.9398 - acc: 0.688 - 0s 19us/step - loss: 1.9214 - acc: 0.6891 - val_loss: 2.2511 - val_acc: 0.6491\n",
      "Epoch 79/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3672 - acc: 0.668 - ETA: 0s - loss: 1.9569 - acc: 0.686 - ETA: 0s - loss: 1.8573 - acc: 0.695 - 0s 18us/step - loss: 1.9057 - acc: 0.6928 - val_loss: 2.2408 - val_acc: 0.6432\n",
      "Epoch 80/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6026 - acc: 0.660 - ETA: 0s - loss: 1.8868 - acc: 0.694 - ETA: 0s - loss: 1.8971 - acc: 0.686 - 0s 18us/step - loss: 1.9110 - acc: 0.6886 - val_loss: 2.3003 - val_acc: 0.6520\n",
      "Epoch 81/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9526 - acc: 0.687 - ETA: 0s - loss: 1.7675 - acc: 0.697 - ETA: 0s - loss: 1.7960 - acc: 0.695 - 0s 18us/step - loss: 1.8579 - acc: 0.6901 - val_loss: 2.3039 - val_acc: 0.6354\n",
      "Epoch 82/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2053 - acc: 0.675 - ETA: 0s - loss: 1.9242 - acc: 0.685 - ETA: 0s - loss: 1.8999 - acc: 0.686 - 0s 17us/step - loss: 1.9142 - acc: 0.6845 - val_loss: 2.3076 - val_acc: 0.6471\n",
      "Epoch 83/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6148 - acc: 0.707 - ETA: 0s - loss: 1.7421 - acc: 0.711 - ETA: 0s - loss: 1.8198 - acc: 0.702 - ETA: 0s - loss: 1.8678 - acc: 0.693 - 0s 19us/step - loss: 1.8566 - acc: 0.6946 - val_loss: 2.3056 - val_acc: 0.6315\n",
      "Epoch 84/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.3082 - acc: 0.746 - ETA: 0s - loss: 1.8360 - acc: 0.701 - ETA: 0s - loss: 1.8600 - acc: 0.694 - ETA: 0s - loss: 1.8914 - acc: 0.690 - 0s 19us/step - loss: 1.8879 - acc: 0.6889 - val_loss: 2.2153 - val_acc: 0.6373\n",
      "Epoch 85/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.4906 - acc: 0.718 - ETA: 0s - loss: 1.7787 - acc: 0.696 - ETA: 0s - loss: 1.7873 - acc: 0.696 - 0s 18us/step - loss: 1.7982 - acc: 0.6922 - val_loss: 2.2040 - val_acc: 0.6315\n",
      "Epoch 86/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5483 - acc: 0.707 - ETA: 0s - loss: 1.7560 - acc: 0.693 - ETA: 0s - loss: 1.7361 - acc: 0.695 - 0s 18us/step - loss: 1.7896 - acc: 0.6894 - val_loss: 2.2179 - val_acc: 0.6422\n",
      "Epoch 87/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.2356 - acc: 0.753 - ETA: 0s - loss: 1.7056 - acc: 0.695 - ETA: 0s - loss: 1.7255 - acc: 0.691 - 0s 18us/step - loss: 1.7538 - acc: 0.6895 - val_loss: 2.2069 - val_acc: 0.6413\n",
      "Epoch 88/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8574 - acc: 0.691 - ETA: 0s - loss: 1.7500 - acc: 0.693 - ETA: 0s - loss: 1.7503 - acc: 0.695 - ETA: 0s - loss: 1.7544 - acc: 0.694 - 0s 19us/step - loss: 1.7569 - acc: 0.6938 - val_loss: 2.1606 - val_acc: 0.6559\n",
      "Epoch 89/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7732 - acc: 0.746 - ETA: 0s - loss: 1.8498 - acc: 0.695 - ETA: 0s - loss: 1.7511 - acc: 0.701 - 0s 18us/step - loss: 1.7609 - acc: 0.6962 - val_loss: 2.1638 - val_acc: 0.6413\n",
      "Epoch 90/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7439 - acc: 0.703 - ETA: 0s - loss: 1.7486 - acc: 0.706 - ETA: 0s - loss: 1.7263 - acc: 0.700 - ETA: 0s - loss: 1.7414 - acc: 0.696 - 0s 20us/step - loss: 1.7383 - acc: 0.6943 - val_loss: 2.1581 - val_acc: 0.6432\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5459 - acc: 0.738 - ETA: 0s - loss: 1.6610 - acc: 0.708 - ETA: 0s - loss: 1.6603 - acc: 0.704 - 0s 18us/step - loss: 1.7084 - acc: 0.7016 - val_loss: 2.1520 - val_acc: 0.6520\n",
      "Epoch 92/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9458 - acc: 0.703 - ETA: 0s - loss: 1.7164 - acc: 0.699 - ETA: 0s - loss: 1.7420 - acc: 0.699 - 0s 18us/step - loss: 1.7206 - acc: 0.6984 - val_loss: 2.1641 - val_acc: 0.6569\n",
      "Epoch 93/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5598 - acc: 0.750 - ETA: 0s - loss: 1.6624 - acc: 0.717 - ETA: 0s - loss: 1.6967 - acc: 0.710 - 0s 18us/step - loss: 1.6991 - acc: 0.7084 - val_loss: 2.1809 - val_acc: 0.6500\n",
      "Epoch 94/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5986 - acc: 0.726 - ETA: 0s - loss: 1.6170 - acc: 0.721 - ETA: 0s - loss: 1.6839 - acc: 0.709 - 0s 18us/step - loss: 1.7164 - acc: 0.7051 - val_loss: 2.2461 - val_acc: 0.6422\n",
      "Epoch 95/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5431 - acc: 0.730 - ETA: 0s - loss: 1.6846 - acc: 0.702 - ETA: 0s - loss: 1.7001 - acc: 0.700 - 0s 17us/step - loss: 1.7058 - acc: 0.6971 - val_loss: 2.2073 - val_acc: 0.6403\n",
      "Epoch 96/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7530 - acc: 0.668 - ETA: 0s - loss: 1.8321 - acc: 0.694 - ETA: 0s - loss: 1.6946 - acc: 0.700 - 0s 18us/step - loss: 1.7169 - acc: 0.6962 - val_loss: 2.1569 - val_acc: 0.6442\n",
      "Epoch 97/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6579 - acc: 0.703 - ETA: 0s - loss: 1.7166 - acc: 0.688 - ETA: 0s - loss: 1.7464 - acc: 0.690 - 0s 17us/step - loss: 1.7250 - acc: 0.6916 - val_loss: 2.1635 - val_acc: 0.6403\n",
      "Epoch 98/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6947 - acc: 0.691 - ETA: 0s - loss: 1.6971 - acc: 0.697 - ETA: 0s - loss: 1.7122 - acc: 0.696 - 0s 18us/step - loss: 1.7225 - acc: 0.6952 - val_loss: 2.1690 - val_acc: 0.6471\n",
      "Epoch 99/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5640 - acc: 0.726 - ETA: 0s - loss: 1.6948 - acc: 0.710 - ETA: 0s - loss: 1.7021 - acc: 0.705 - 0s 18us/step - loss: 1.6985 - acc: 0.7044 - val_loss: 2.1574 - val_acc: 0.6588\n",
      "Epoch 100/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.4320 - acc: 0.730 - ETA: 0s - loss: 1.6668 - acc: 0.699 - ETA: 0s - loss: 1.6905 - acc: 0.701 - 0s 18us/step - loss: 1.7253 - acc: 0.6993 - val_loss: 2.1788 - val_acc: 0.6481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c72e3f2ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_based_model.fit(vgg_features, y_train, batch_size=256, epochs=EPOCHS, callbacks=callbacks, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_features = resnet50_features_extractor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_based_model = create_simple_model(num_classes, resnet50_features_extractor.model.output.get_shape().as_list()[1:])\n",
    "resnet50_based_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "if NOT_KAGGLE_KERNEL:\n",
    "    callbacks = [TensorBoard('./data/logs/resnet50-{0}'.format(datetime.now().isoformat().replace(':','-')))]\n",
    "else:\n",
    "    callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/100\n",
      "9199/9199 [==============================] - ETA: 6s - loss: 6.1272 - acc: 0.011 - ETA: 0s - loss: 5.5317 - acc: 0.023 - ETA: 0s - loss: 5.0511 - acc: 0.044 - ETA: 0s - loss: 4.5269 - acc: 0.094 - ETA: 0s - loss: 4.0939 - acc: 0.146 - 1s 63us/step - loss: 3.8938 - acc: 0.1713 - val_loss: 1.7258 - val_acc: 0.5963\n",
      "Epoch 2/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1010 - acc: 0.449 - ETA: 0s - loss: 1.9940 - acc: 0.474 - ETA: 0s - loss: 1.8797 - acc: 0.502 - ETA: 0s - loss: 1.7909 - acc: 0.524 - ETA: 0s - loss: 1.7185 - acc: 0.539 - 0s 27us/step - loss: 1.6979 - acc: 0.5452 - val_loss: 1.1000 - val_acc: 0.7038\n",
      "Epoch 3/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.3650 - acc: 0.605 - ETA: 0s - loss: 1.2710 - acc: 0.631 - ETA: 0s - loss: 1.2229 - acc: 0.648 - ETA: 0s - loss: 1.2057 - acc: 0.656 - ETA: 0s - loss: 1.1790 - acc: 0.663 - 0s 27us/step - loss: 1.1742 - acc: 0.6647 - val_loss: 0.9237 - val_acc: 0.7175\n",
      "Epoch 4/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.8007 - acc: 0.746 - ETA: 0s - loss: 0.9603 - acc: 0.725 - ETA: 0s - loss: 0.9501 - acc: 0.727 - ETA: 0s - loss: 0.9396 - acc: 0.729 - ETA: 0s - loss: 0.9309 - acc: 0.733 - 0s 29us/step - loss: 0.9268 - acc: 0.7341 - val_loss: 0.8476 - val_acc: 0.7419\n",
      "Epoch 5/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.7148 - acc: 0.812 - ETA: 0s - loss: 0.8162 - acc: 0.768 - ETA: 0s - loss: 0.7964 - acc: 0.769 - ETA: 0s - loss: 0.7888 - acc: 0.772 - ETA: 0s - loss: 0.7922 - acc: 0.768 - 0s 27us/step - loss: 0.7926 - acc: 0.7687 - val_loss: 0.7994 - val_acc: 0.7498\n",
      "Epoch 6/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.7040 - acc: 0.789 - ETA: 0s - loss: 0.7428 - acc: 0.787 - ETA: 0s - loss: 0.7053 - acc: 0.795 - ETA: 0s - loss: 0.6931 - acc: 0.796 - ETA: 0s - loss: 0.6850 - acc: 0.798 - 0s 27us/step - loss: 0.6849 - acc: 0.7982 - val_loss: 0.7826 - val_acc: 0.7390\n",
      "Epoch 7/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.6213 - acc: 0.800 - ETA: 0s - loss: 0.6170 - acc: 0.816 - ETA: 0s - loss: 0.6115 - acc: 0.819 - ETA: 0s - loss: 0.6055 - acc: 0.821 - ETA: 0s - loss: 0.5998 - acc: 0.822 - 0s 28us/step - loss: 0.5974 - acc: 0.8228 - val_loss: 0.7826 - val_acc: 0.7429\n",
      "Epoch 8/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.5674 - acc: 0.832 - ETA: 0s - loss: 0.5328 - acc: 0.846 - ETA: 0s - loss: 0.5252 - acc: 0.844 - ETA: 0s - loss: 0.5305 - acc: 0.844 - ETA: 0s - loss: 0.5270 - acc: 0.843 - 0s 29us/step - loss: 0.5286 - acc: 0.8428 - val_loss: 0.7519 - val_acc: 0.7576\n",
      "Epoch 9/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.5042 - acc: 0.851 - ETA: 0s - loss: 0.4638 - acc: 0.865 - ETA: 0s - loss: 0.4797 - acc: 0.857 - ETA: 0s - loss: 0.4780 - acc: 0.857 - ETA: 0s - loss: 0.4837 - acc: 0.855 - 0s 28us/step - loss: 0.4836 - acc: 0.8559 - val_loss: 0.7299 - val_acc: 0.7713\n",
      "Epoch 10/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.4285 - acc: 0.875 - ETA: 0s - loss: 0.4284 - acc: 0.866 - ETA: 0s - loss: 0.4358 - acc: 0.868 - ETA: 0s - loss: 0.4320 - acc: 0.871 - ETA: 0s - loss: 0.4258 - acc: 0.874 - 0s 28us/step - loss: 0.4279 - acc: 0.8726 - val_loss: 0.7324 - val_acc: 0.7605\n",
      "Epoch 11/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.4174 - acc: 0.867 - ETA: 0s - loss: 0.4104 - acc: 0.882 - ETA: 0s - loss: 0.4074 - acc: 0.878 - ETA: 0s - loss: 0.4134 - acc: 0.875 - ETA: 0s - loss: 0.4065 - acc: 0.879 - 0s 27us/step - loss: 0.4073 - acc: 0.8796 - val_loss: 0.7370 - val_acc: 0.7634\n",
      "Epoch 12/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.3530 - acc: 0.878 - ETA: 0s - loss: 0.3665 - acc: 0.883 - ETA: 0s - loss: 0.3744 - acc: 0.886 - ETA: 0s - loss: 0.3689 - acc: 0.891 - ETA: 0s - loss: 0.3725 - acc: 0.891 - 0s 27us/step - loss: 0.3704 - acc: 0.8917 - val_loss: 0.7287 - val_acc: 0.7654\n",
      "Epoch 13/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.2770 - acc: 0.906 - ETA: 0s - loss: 0.3292 - acc: 0.905 - ETA: 0s - loss: 0.3289 - acc: 0.908 - ETA: 0s - loss: 0.3379 - acc: 0.906 - ETA: 0s - loss: 0.3382 - acc: 0.904 - 0s 27us/step - loss: 0.3385 - acc: 0.9046 - val_loss: 0.7123 - val_acc: 0.7742\n",
      "Epoch 14/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.3957 - acc: 0.875 - ETA: 0s - loss: 0.3075 - acc: 0.908 - ETA: 0s - loss: 0.3114 - acc: 0.908 - ETA: 0s - loss: 0.3178 - acc: 0.906 - ETA: 0s - loss: 0.3150 - acc: 0.907 - 0s 28us/step - loss: 0.3146 - acc: 0.9083 - val_loss: 0.7147 - val_acc: 0.7683\n",
      "Epoch 15/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.2990 - acc: 0.921 - ETA: 0s - loss: 0.3067 - acc: 0.907 - ETA: 0s - loss: 0.2998 - acc: 0.912 - ETA: 0s - loss: 0.3006 - acc: 0.913 - ETA: 0s - loss: 0.3007 - acc: 0.915 - 0s 27us/step - loss: 0.3015 - acc: 0.9139 - val_loss: 0.7192 - val_acc: 0.7683\n",
      "Epoch 16/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.2821 - acc: 0.925 - ETA: 0s - loss: 0.2705 - acc: 0.929 - ETA: 0s - loss: 0.2689 - acc: 0.927 - ETA: 0s - loss: 0.2665 - acc: 0.928 - ETA: 0s - loss: 0.2675 - acc: 0.929 - 0s 28us/step - loss: 0.2668 - acc: 0.9290 - val_loss: 0.7248 - val_acc: 0.7615\n",
      "Epoch 17/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.2667 - acc: 0.933 - ETA: 0s - loss: 0.2596 - acc: 0.927 - ETA: 0s - loss: 0.2497 - acc: 0.929 - ETA: 0s - loss: 0.2455 - acc: 0.931 - ETA: 0s - loss: 0.2506 - acc: 0.930 - 0s 28us/step - loss: 0.2527 - acc: 0.9290 - val_loss: 0.7156 - val_acc: 0.7654\n",
      "Epoch 18/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.2131 - acc: 0.945 - ETA: 0s - loss: 0.2539 - acc: 0.928 - ETA: 0s - loss: 0.2516 - acc: 0.932 - ETA: 0s - loss: 0.2527 - acc: 0.929 - ETA: 0s - loss: 0.2533 - acc: 0.929 - 0s 29us/step - loss: 0.2542 - acc: 0.9291 - val_loss: 0.7222 - val_acc: 0.7683\n",
      "Epoch 19/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1844 - acc: 0.960 - ETA: 0s - loss: 0.2169 - acc: 0.945 - ETA: 0s - loss: 0.2169 - acc: 0.944 - ETA: 0s - loss: 0.2231 - acc: 0.938 - ETA: 0s - loss: 0.2283 - acc: 0.936 - 0s 29us/step - loss: 0.2286 - acc: 0.9368 - val_loss: 0.7426 - val_acc: 0.7703\n",
      "Epoch 20/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.2012 - acc: 0.949 - ETA: 0s - loss: 0.2002 - acc: 0.948 - ETA: 0s - loss: 0.2076 - acc: 0.945 - ETA: 0s - loss: 0.2050 - acc: 0.946 - ETA: 0s - loss: 0.2075 - acc: 0.945 - 0s 28us/step - loss: 0.2096 - acc: 0.9449 - val_loss: 0.7301 - val_acc: 0.7781\n",
      "Epoch 21/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1700 - acc: 0.953 - ETA: 0s - loss: 0.2118 - acc: 0.944 - ETA: 0s - loss: 0.2076 - acc: 0.945 - ETA: 0s - loss: 0.2111 - acc: 0.946 - ETA: 0s - loss: 0.2107 - acc: 0.944 - 0s 27us/step - loss: 0.2101 - acc: 0.9442 - val_loss: 0.7422 - val_acc: 0.7742\n",
      "Epoch 22/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.2240 - acc: 0.941 - ETA: 0s - loss: 0.2010 - acc: 0.949 - ETA: 0s - loss: 0.1918 - acc: 0.952 - ETA: 0s - loss: 0.1960 - acc: 0.951 - ETA: 0s - loss: 0.1971 - acc: 0.948 - 0s 28us/step - loss: 0.1989 - acc: 0.9466 - val_loss: 0.7443 - val_acc: 0.7693\n",
      "Epoch 23/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1407 - acc: 0.972 - ETA: 0s - loss: 0.1826 - acc: 0.952 - ETA: 0s - loss: 0.1822 - acc: 0.952 - ETA: 0s - loss: 0.1881 - acc: 0.950 - ETA: 0s - loss: 0.1882 - acc: 0.950 - 0s 27us/step - loss: 0.1891 - acc: 0.9503 - val_loss: 0.7256 - val_acc: 0.7664\n",
      "Epoch 24/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1691 - acc: 0.953 - ETA: 0s - loss: 0.1763 - acc: 0.954 - ETA: 0s - loss: 0.1755 - acc: 0.955 - ETA: 0s - loss: 0.1757 - acc: 0.955 - ETA: 0s - loss: 0.1786 - acc: 0.953 - 0s 28us/step - loss: 0.1825 - acc: 0.9515 - val_loss: 0.7320 - val_acc: 0.7722\n",
      "Epoch 25/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1619 - acc: 0.964 - ETA: 0s - loss: 0.1577 - acc: 0.960 - ETA: 0s - loss: 0.1639 - acc: 0.959 - ETA: 0s - loss: 0.1668 - acc: 0.957 - ETA: 0s - loss: 0.1718 - acc: 0.955 - 0s 27us/step - loss: 0.1722 - acc: 0.9552 - val_loss: 0.7209 - val_acc: 0.7791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1404 - acc: 0.976 - ETA: 0s - loss: 0.1574 - acc: 0.962 - ETA: 0s - loss: 0.1632 - acc: 0.959 - ETA: 0s - loss: 0.1658 - acc: 0.958 - ETA: 0s - loss: 0.1677 - acc: 0.957 - 0s 27us/step - loss: 0.1696 - acc: 0.9564 - val_loss: 0.7203 - val_acc: 0.7732\n",
      "Epoch 27/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1431 - acc: 0.972 - ETA: 0s - loss: 0.1657 - acc: 0.957 - ETA: 0s - loss: 0.1580 - acc: 0.961 - ETA: 0s - loss: 0.1592 - acc: 0.959 - ETA: 0s - loss: 0.1613 - acc: 0.959 - 0s 27us/step - loss: 0.1619 - acc: 0.9589 - val_loss: 0.7436 - val_acc: 0.7586\n",
      "Epoch 28/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1334 - acc: 0.968 - ETA: 0s - loss: 0.1471 - acc: 0.965 - ETA: 0s - loss: 0.1508 - acc: 0.962 - ETA: 0s - loss: 0.1532 - acc: 0.962 - ETA: 0s - loss: 0.1563 - acc: 0.961 - 0s 27us/step - loss: 0.1569 - acc: 0.9604 - val_loss: 0.7455 - val_acc: 0.7781\n",
      "Epoch 29/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1417 - acc: 0.953 - ETA: 0s - loss: 0.1491 - acc: 0.962 - ETA: 0s - loss: 0.1472 - acc: 0.964 - ETA: 0s - loss: 0.1486 - acc: 0.962 - 0s 26us/step - loss: 0.1499 - acc: 0.9624 - val_loss: 0.7401 - val_acc: 0.7791\n",
      "Epoch 30/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1253 - acc: 0.972 - ETA: 0s - loss: 0.1347 - acc: 0.970 - ETA: 0s - loss: 0.1367 - acc: 0.968 - ETA: 0s - loss: 0.1390 - acc: 0.966 - ETA: 0s - loss: 0.1420 - acc: 0.964 - 0s 27us/step - loss: 0.1419 - acc: 0.9647 - val_loss: 0.7390 - val_acc: 0.7761\n",
      "Epoch 31/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1144 - acc: 0.976 - ETA: 0s - loss: 0.1344 - acc: 0.970 - ETA: 0s - loss: 0.1360 - acc: 0.967 - ETA: 0s - loss: 0.1398 - acc: 0.966 - ETA: 0s - loss: 0.1408 - acc: 0.965 - 0s 27us/step - loss: 0.1403 - acc: 0.9659 - val_loss: 0.7502 - val_acc: 0.7644\n",
      "Epoch 32/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1219 - acc: 0.972 - ETA: 0s - loss: 0.1279 - acc: 0.967 - ETA: 0s - loss: 0.1241 - acc: 0.969 - ETA: 0s - loss: 0.1317 - acc: 0.967 - ETA: 0s - loss: 0.1350 - acc: 0.967 - 0s 27us/step - loss: 0.1360 - acc: 0.9665 - val_loss: 0.7600 - val_acc: 0.7683\n",
      "Epoch 33/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1152 - acc: 0.976 - ETA: 0s - loss: 0.1271 - acc: 0.969 - ETA: 0s - loss: 0.1366 - acc: 0.965 - ETA: 0s - loss: 0.1363 - acc: 0.965 - ETA: 0s - loss: 0.1360 - acc: 0.964 - 0s 26us/step - loss: 0.1371 - acc: 0.9636 - val_loss: 0.7672 - val_acc: 0.7781\n",
      "Epoch 34/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1446 - acc: 0.960 - ETA: 0s - loss: 0.1318 - acc: 0.965 - ETA: 0s - loss: 0.1253 - acc: 0.969 - ETA: 0s - loss: 0.1295 - acc: 0.968 - ETA: 0s - loss: 0.1290 - acc: 0.968 - 0s 27us/step - loss: 0.1295 - acc: 0.9689 - val_loss: 0.7675 - val_acc: 0.7654\n",
      "Epoch 35/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1181 - acc: 0.964 - ETA: 0s - loss: 0.1173 - acc: 0.973 - ETA: 0s - loss: 0.1169 - acc: 0.973 - ETA: 0s - loss: 0.1181 - acc: 0.972 - ETA: 0s - loss: 0.1214 - acc: 0.970 - 0s 28us/step - loss: 0.1235 - acc: 0.9703 - val_loss: 0.7573 - val_acc: 0.7713\n",
      "Epoch 36/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1348 - acc: 0.964 - ETA: 0s - loss: 0.1215 - acc: 0.971 - ETA: 0s - loss: 0.1261 - acc: 0.968 - ETA: 0s - loss: 0.1249 - acc: 0.968 - ETA: 0s - loss: 0.1251 - acc: 0.968 - 0s 27us/step - loss: 0.1253 - acc: 0.9684 - val_loss: 0.7797 - val_acc: 0.7752\n",
      "Epoch 37/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1027 - acc: 0.980 - ETA: 0s - loss: 0.1169 - acc: 0.972 - ETA: 0s - loss: 0.1213 - acc: 0.969 - ETA: 0s - loss: 0.1231 - acc: 0.968 - ETA: 0s - loss: 0.1228 - acc: 0.968 - 0s 26us/step - loss: 0.1224 - acc: 0.9687 - val_loss: 0.7668 - val_acc: 0.7713\n",
      "Epoch 38/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0881 - acc: 0.984 - ETA: 0s - loss: 0.1217 - acc: 0.967 - ETA: 0s - loss: 0.1141 - acc: 0.970 - ETA: 0s - loss: 0.1170 - acc: 0.970 - ETA: 0s - loss: 0.1185 - acc: 0.969 - 0s 27us/step - loss: 0.1192 - acc: 0.9702 - val_loss: 0.7505 - val_acc: 0.7742\n",
      "Epoch 39/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0976 - acc: 0.980 - ETA: 0s - loss: 0.1059 - acc: 0.975 - ETA: 0s - loss: 0.1077 - acc: 0.975 - ETA: 0s - loss: 0.1102 - acc: 0.973 - ETA: 0s - loss: 0.1126 - acc: 0.972 - 0s 27us/step - loss: 0.1129 - acc: 0.9724 - val_loss: 0.7770 - val_acc: 0.7752\n",
      "Epoch 40/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1260 - acc: 0.972 - ETA: 0s - loss: 0.1168 - acc: 0.971 - ETA: 0s - loss: 0.1172 - acc: 0.971 - ETA: 0s - loss: 0.1167 - acc: 0.971 - ETA: 0s - loss: 0.1173 - acc: 0.970 - 0s 27us/step - loss: 0.1164 - acc: 0.9705 - val_loss: 0.7731 - val_acc: 0.7781\n",
      "Epoch 41/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1264 - acc: 0.957 - ETA: 0s - loss: 0.1021 - acc: 0.977 - ETA: 0s - loss: 0.1054 - acc: 0.975 - ETA: 0s - loss: 0.1089 - acc: 0.974 - ETA: 0s - loss: 0.1100 - acc: 0.973 - 0s 27us/step - loss: 0.1094 - acc: 0.9740 - val_loss: 0.7794 - val_acc: 0.7742\n",
      "Epoch 42/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1203 - acc: 0.960 - ETA: 0s - loss: 0.1041 - acc: 0.976 - ETA: 0s - loss: 0.1019 - acc: 0.977 - ETA: 0s - loss: 0.1024 - acc: 0.978 - ETA: 0s - loss: 0.1017 - acc: 0.978 - 0s 27us/step - loss: 0.1031 - acc: 0.9777 - val_loss: 0.7823 - val_acc: 0.7683\n",
      "Epoch 43/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0965 - acc: 0.972 - ETA: 0s - loss: 0.0969 - acc: 0.976 - ETA: 0s - loss: 0.1019 - acc: 0.974 - ETA: 0s - loss: 0.1013 - acc: 0.976 - ETA: 0s - loss: 0.1035 - acc: 0.974 - 0s 27us/step - loss: 0.1036 - acc: 0.9745 - val_loss: 0.7829 - val_acc: 0.7644\n",
      "Epoch 44/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0974 - acc: 0.988 - ETA: 0s - loss: 0.0985 - acc: 0.979 - ETA: 0s - loss: 0.0999 - acc: 0.977 - ETA: 0s - loss: 0.1032 - acc: 0.975 - ETA: 0s - loss: 0.1038 - acc: 0.975 - 0s 27us/step - loss: 0.1039 - acc: 0.9758 - val_loss: 0.7833 - val_acc: 0.7722\n",
      "Epoch 45/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1309 - acc: 0.953 - ETA: 0s - loss: 0.0968 - acc: 0.974 - ETA: 0s - loss: 0.0996 - acc: 0.975 - ETA: 0s - loss: 0.1015 - acc: 0.975 - ETA: 0s - loss: 0.1051 - acc: 0.973 - 0s 27us/step - loss: 0.1052 - acc: 0.9730 - val_loss: 0.8025 - val_acc: 0.7674\n",
      "Epoch 46/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0955 - acc: 0.980 - ETA: 0s - loss: 0.1020 - acc: 0.974 - ETA: 0s - loss: 0.0994 - acc: 0.975 - ETA: 0s - loss: 0.0948 - acc: 0.977 - ETA: 0s - loss: 0.0978 - acc: 0.975 - 0s 28us/step - loss: 0.0982 - acc: 0.9758 - val_loss: 0.7868 - val_acc: 0.7683\n",
      "Epoch 47/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.980 - ETA: 0s - loss: 0.0910 - acc: 0.979 - ETA: 0s - loss: 0.0889 - acc: 0.979 - ETA: 0s - loss: 0.0904 - acc: 0.979 - ETA: 0s - loss: 0.0956 - acc: 0.977 - 0s 28us/step - loss: 0.0961 - acc: 0.9770 - val_loss: 0.7907 - val_acc: 0.7644\n",
      "Epoch 48/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0974 - acc: 0.976 - ETA: 0s - loss: 0.1022 - acc: 0.973 - ETA: 0s - loss: 0.0953 - acc: 0.976 - ETA: 0s - loss: 0.0948 - acc: 0.976 - ETA: 0s - loss: 0.0920 - acc: 0.977 - 0s 27us/step - loss: 0.0923 - acc: 0.9774 - val_loss: 0.7806 - val_acc: 0.7732\n",
      "Epoch 49/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1112 - acc: 0.968 - ETA: 0s - loss: 0.0952 - acc: 0.977 - ETA: 0s - loss: 0.0984 - acc: 0.975 - ETA: 0s - loss: 0.0984 - acc: 0.976 - ETA: 0s - loss: 0.0969 - acc: 0.976 - 0s 27us/step - loss: 0.0967 - acc: 0.9756 - val_loss: 0.8058 - val_acc: 0.7713\n",
      "Epoch 50/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0988 - acc: 0.980 - ETA: 0s - loss: 0.0950 - acc: 0.976 - ETA: 0s - loss: 0.0896 - acc: 0.977 - ETA: 0s - loss: 0.0934 - acc: 0.976 - ETA: 0s - loss: 0.0944 - acc: 0.975 - 0s 27us/step - loss: 0.0950 - acc: 0.9752 - val_loss: 0.7888 - val_acc: 0.7771\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0922 - acc: 0.976 - ETA: 0s - loss: 0.0910 - acc: 0.976 - ETA: 0s - loss: 0.0909 - acc: 0.974 - ETA: 0s - loss: 0.0946 - acc: 0.972 - 0s 25us/step - loss: 0.0936 - acc: 0.9736 - val_loss: 0.8013 - val_acc: 0.7693\n",
      "Epoch 52/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0650 - acc: 0.988 - ETA: 0s - loss: 0.0801 - acc: 0.980 - ETA: 0s - loss: 0.0873 - acc: 0.977 - ETA: 0s - loss: 0.0903 - acc: 0.975 - 0s 26us/step - loss: 0.0904 - acc: 0.9758 - val_loss: 0.8135 - val_acc: 0.7713\n",
      "Epoch 53/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1078 - acc: 0.960 - ETA: 0s - loss: 0.0939 - acc: 0.976 - ETA: 0s - loss: 0.0903 - acc: 0.977 - ETA: 0s - loss: 0.0902 - acc: 0.977 - ETA: 0s - loss: 0.0893 - acc: 0.977 - 0s 28us/step - loss: 0.0891 - acc: 0.9777 - val_loss: 0.7986 - val_acc: 0.7693\n",
      "Epoch 54/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0708 - acc: 0.984 - ETA: 0s - loss: 0.0840 - acc: 0.978 - ETA: 0s - loss: 0.0818 - acc: 0.980 - ETA: 0s - loss: 0.0822 - acc: 0.979 - ETA: 0s - loss: 0.0823 - acc: 0.979 - 0s 27us/step - loss: 0.0820 - acc: 0.9800 - val_loss: 0.8056 - val_acc: 0.7634\n",
      "Epoch 55/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0543 - acc: 0.996 - ETA: 0s - loss: 0.0828 - acc: 0.980 - ETA: 0s - loss: 0.0863 - acc: 0.979 - ETA: 0s - loss: 0.0880 - acc: 0.979 - ETA: 0s - loss: 0.0885 - acc: 0.977 - 0s 27us/step - loss: 0.0885 - acc: 0.9772 - val_loss: 0.8137 - val_acc: 0.7752\n",
      "Epoch 56/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1059 - acc: 0.968 - ETA: 0s - loss: 0.0784 - acc: 0.982 - ETA: 0s - loss: 0.0816 - acc: 0.980 - ETA: 0s - loss: 0.0810 - acc: 0.981 - ETA: 0s - loss: 0.0802 - acc: 0.981 - 0s 28us/step - loss: 0.0807 - acc: 0.9814 - val_loss: 0.7916 - val_acc: 0.7810\n",
      "Epoch 57/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1179 - acc: 0.972 - ETA: 0s - loss: 0.0819 - acc: 0.981 - ETA: 0s - loss: 0.0819 - acc: 0.981 - ETA: 0s - loss: 0.0819 - acc: 0.980 - ETA: 0s - loss: 0.0811 - acc: 0.979 - 0s 27us/step - loss: 0.0812 - acc: 0.9799 - val_loss: 0.8051 - val_acc: 0.7713\n",
      "Epoch 58/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0833 - acc: 0.972 - ETA: 0s - loss: 0.0754 - acc: 0.981 - ETA: 0s - loss: 0.0773 - acc: 0.981 - ETA: 0s - loss: 0.0813 - acc: 0.979 - ETA: 0s - loss: 0.0828 - acc: 0.978 - 0s 27us/step - loss: 0.0831 - acc: 0.9786 - val_loss: 0.7901 - val_acc: 0.7781\n",
      "Epoch 59/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0756 - acc: 0.984 - ETA: 0s - loss: 0.0667 - acc: 0.984 - ETA: 0s - loss: 0.0687 - acc: 0.984 - ETA: 0s - loss: 0.0723 - acc: 0.983 - ETA: 0s - loss: 0.0742 - acc: 0.981 - 0s 27us/step - loss: 0.0742 - acc: 0.9814 - val_loss: 0.8144 - val_acc: 0.7713\n",
      "Epoch 60/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0459 - acc: 0.992 - ETA: 0s - loss: 0.0716 - acc: 0.983 - ETA: 0s - loss: 0.0727 - acc: 0.983 - ETA: 0s - loss: 0.0755 - acc: 0.981 - 0s 26us/step - loss: 0.0779 - acc: 0.9807 - val_loss: 0.8006 - val_acc: 0.7761\n",
      "Epoch 61/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0718 - acc: 0.988 - ETA: 0s - loss: 0.0782 - acc: 0.982 - ETA: 0s - loss: 0.0788 - acc: 0.981 - ETA: 0s - loss: 0.0805 - acc: 0.980 - ETA: 0s - loss: 0.0785 - acc: 0.981 - 0s 29us/step - loss: 0.0784 - acc: 0.9813 - val_loss: 0.8063 - val_acc: 0.7849\n",
      "Epoch 62/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0927 - acc: 0.976 - ETA: 0s - loss: 0.0774 - acc: 0.978 - ETA: 0s - loss: 0.0778 - acc: 0.978 - ETA: 0s - loss: 0.0775 - acc: 0.978 - ETA: 0s - loss: 0.0768 - acc: 0.979 - 0s 28us/step - loss: 0.0753 - acc: 0.9805 - val_loss: 0.8187 - val_acc: 0.7693\n",
      "Epoch 63/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0652 - acc: 0.980 - ETA: 0s - loss: 0.0690 - acc: 0.983 - ETA: 0s - loss: 0.0726 - acc: 0.981 - ETA: 0s - loss: 0.0741 - acc: 0.981 - ETA: 0s - loss: 0.0773 - acc: 0.979 - 0s 26us/step - loss: 0.0768 - acc: 0.9800 - val_loss: 0.8200 - val_acc: 0.7722\n",
      "Epoch 64/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0980 - acc: 0.976 - ETA: 0s - loss: 0.0779 - acc: 0.979 - ETA: 0s - loss: 0.0800 - acc: 0.980 - ETA: 0s - loss: 0.0784 - acc: 0.981 - ETA: 0s - loss: 0.0774 - acc: 0.981 - 0s 27us/step - loss: 0.0780 - acc: 0.9817 - val_loss: 0.8178 - val_acc: 0.7801\n",
      "Epoch 65/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0567 - acc: 0.996 - ETA: 0s - loss: 0.0720 - acc: 0.981 - ETA: 0s - loss: 0.0733 - acc: 0.982 - ETA: 0s - loss: 0.0741 - acc: 0.981 - ETA: 0s - loss: 0.0754 - acc: 0.980 - 0s 28us/step - loss: 0.0754 - acc: 0.9802 - val_loss: 0.8352 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0769 - acc: 0.972 - ETA: 0s - loss: 0.0673 - acc: 0.982 - ETA: 0s - loss: 0.0695 - acc: 0.982 - ETA: 0s - loss: 0.0711 - acc: 0.981 - ETA: 0s - loss: 0.0717 - acc: 0.980 - 0s 28us/step - loss: 0.0719 - acc: 0.9811 - val_loss: 0.8328 - val_acc: 0.7683\n",
      "Epoch 67/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0719 - acc: 0.984 - ETA: 0s - loss: 0.0659 - acc: 0.983 - ETA: 0s - loss: 0.0733 - acc: 0.981 - ETA: 0s - loss: 0.0750 - acc: 0.981 - ETA: 0s - loss: 0.0751 - acc: 0.981 - 0s 27us/step - loss: 0.0753 - acc: 0.9811 - val_loss: 0.8402 - val_acc: 0.7664\n",
      "Epoch 68/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0653 - acc: 0.988 - ETA: 0s - loss: 0.0667 - acc: 0.984 - ETA: 0s - loss: 0.0713 - acc: 0.981 - ETA: 0s - loss: 0.0684 - acc: 0.982 - ETA: 0s - loss: 0.0703 - acc: 0.981 - 0s 28us/step - loss: 0.0708 - acc: 0.9816 - val_loss: 0.8277 - val_acc: 0.7664\n",
      "Epoch 69/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0562 - acc: 0.988 - ETA: 0s - loss: 0.0711 - acc: 0.980 - ETA: 0s - loss: 0.0775 - acc: 0.978 - ETA: 0s - loss: 0.0738 - acc: 0.980 - ETA: 0s - loss: 0.0724 - acc: 0.980 - 0s 27us/step - loss: 0.0717 - acc: 0.9805 - val_loss: 0.8352 - val_acc: 0.7732\n",
      "Epoch 70/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0584 - acc: 0.980 - ETA: 0s - loss: 0.0683 - acc: 0.983 - ETA: 0s - loss: 0.0692 - acc: 0.982 - ETA: 0s - loss: 0.0715 - acc: 0.980 - ETA: 0s - loss: 0.0694 - acc: 0.981 - 0s 28us/step - loss: 0.0693 - acc: 0.9821 - val_loss: 0.8574 - val_acc: 0.7722\n",
      "Epoch 71/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0900 - acc: 0.968 - ETA: 0s - loss: 0.0661 - acc: 0.981 - ETA: 0s - loss: 0.0707 - acc: 0.980 - ETA: 0s - loss: 0.0717 - acc: 0.980 - ETA: 0s - loss: 0.0726 - acc: 0.979 - 0s 27us/step - loss: 0.0723 - acc: 0.9800 - val_loss: 0.8445 - val_acc: 0.7625\n",
      "Epoch 72/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0795 - acc: 0.980 - ETA: 0s - loss: 0.0841 - acc: 0.974 - ETA: 0s - loss: 0.0716 - acc: 0.979 - ETA: 0s - loss: 0.0735 - acc: 0.979 - ETA: 0s - loss: 0.0705 - acc: 0.980 - 0s 27us/step - loss: 0.0705 - acc: 0.9803 - val_loss: 0.8597 - val_acc: 0.7693\n",
      "Epoch 73/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0781 - acc: 0.968 - ETA: 0s - loss: 0.0727 - acc: 0.979 - ETA: 0s - loss: 0.0735 - acc: 0.980 - ETA: 0s - loss: 0.0722 - acc: 0.981 - ETA: 0s - loss: 0.0721 - acc: 0.981 - 0s 27us/step - loss: 0.0715 - acc: 0.9814 - val_loss: 0.8288 - val_acc: 0.7761\n",
      "Epoch 74/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0496 - acc: 0.992 - ETA: 0s - loss: 0.0550 - acc: 0.989 - ETA: 0s - loss: 0.0612 - acc: 0.986 - ETA: 0s - loss: 0.0639 - acc: 0.985 - ETA: 0s - loss: 0.0661 - acc: 0.984 - 0s 28us/step - loss: 0.0654 - acc: 0.9842 - val_loss: 0.8424 - val_acc: 0.7791\n",
      "Epoch 75/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0671 - acc: 0.976 - ETA: 0s - loss: 0.0679 - acc: 0.982 - ETA: 0s - loss: 0.0641 - acc: 0.983 - ETA: 0s - loss: 0.0658 - acc: 0.983 - ETA: 0s - loss: 0.0656 - acc: 0.983 - 0s 27us/step - loss: 0.0664 - acc: 0.9832 - val_loss: 0.8639 - val_acc: 0.7693\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.992 - ETA: 0s - loss: 0.0630 - acc: 0.983 - ETA: 0s - loss: 0.0628 - acc: 0.983 - ETA: 0s - loss: 0.0605 - acc: 0.984 - ETA: 0s - loss: 0.0604 - acc: 0.984 - 0s 27us/step - loss: 0.0605 - acc: 0.9843 - val_loss: 0.8639 - val_acc: 0.7664\n",
      "Epoch 77/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0553 - acc: 0.980 - ETA: 0s - loss: 0.0602 - acc: 0.982 - ETA: 0s - loss: 0.0632 - acc: 0.983 - ETA: 0s - loss: 0.0640 - acc: 0.982 - ETA: 0s - loss: 0.0648 - acc: 0.982 - 0s 27us/step - loss: 0.0644 - acc: 0.9827 - val_loss: 0.8365 - val_acc: 0.7771\n",
      "Epoch 78/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0412 - acc: 0.996 - ETA: 0s - loss: 0.0530 - acc: 0.989 - ETA: 0s - loss: 0.0546 - acc: 0.987 - ETA: 0s - loss: 0.0571 - acc: 0.986 - ETA: 0s - loss: 0.0572 - acc: 0.986 - 0s 28us/step - loss: 0.0586 - acc: 0.9852 - val_loss: 0.8481 - val_acc: 0.7781\n",
      "Epoch 79/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0642 - acc: 0.980 - ETA: 0s - loss: 0.0659 - acc: 0.982 - ETA: 0s - loss: 0.0589 - acc: 0.985 - ETA: 0s - loss: 0.0619 - acc: 0.985 - ETA: 0s - loss: 0.0640 - acc: 0.984 - 0s 27us/step - loss: 0.0644 - acc: 0.9845 - val_loss: 0.8325 - val_acc: 0.7674\n",
      "Epoch 80/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0704 - acc: 0.984 - ETA: 0s - loss: 0.0696 - acc: 0.982 - ETA: 0s - loss: 0.0664 - acc: 0.981 - ETA: 0s - loss: 0.0663 - acc: 0.982 - ETA: 0s - loss: 0.0665 - acc: 0.982 - 0s 26us/step - loss: 0.0663 - acc: 0.9825 - val_loss: 0.8850 - val_acc: 0.7634\n",
      "Epoch 81/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.1175 - acc: 0.957 - ETA: 0s - loss: 0.0720 - acc: 0.977 - ETA: 0s - loss: 0.0688 - acc: 0.982 - ETA: 0s - loss: 0.0694 - acc: 0.981 - ETA: 0s - loss: 0.0676 - acc: 0.982 - 0s 27us/step - loss: 0.0674 - acc: 0.9821 - val_loss: 0.8752 - val_acc: 0.7586\n",
      "Epoch 82/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0563 - acc: 0.972 - ETA: 0s - loss: 0.0659 - acc: 0.978 - ETA: 0s - loss: 0.0634 - acc: 0.980 - ETA: 0s - loss: 0.0677 - acc: 0.979 - ETA: 0s - loss: 0.0673 - acc: 0.979 - 0s 28us/step - loss: 0.0679 - acc: 0.9790 - val_loss: 0.8726 - val_acc: 0.7566\n",
      "Epoch 83/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0927 - acc: 0.957 - ETA: 0s - loss: 0.0536 - acc: 0.985 - ETA: 0s - loss: 0.0550 - acc: 0.985 - ETA: 0s - loss: 0.0552 - acc: 0.986 - ETA: 0s - loss: 0.0559 - acc: 0.985 - 0s 27us/step - loss: 0.0562 - acc: 0.9858 - val_loss: 0.8856 - val_acc: 0.7615\n",
      "Epoch 84/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0782 - acc: 0.972 - ETA: 0s - loss: 0.0644 - acc: 0.981 - ETA: 0s - loss: 0.0624 - acc: 0.981 - ETA: 0s - loss: 0.0597 - acc: 0.983 - ETA: 0s - loss: 0.0589 - acc: 0.984 - 0s 29us/step - loss: 0.0583 - acc: 0.9846 - val_loss: 0.8791 - val_acc: 0.7644\n",
      "Epoch 85/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0425 - acc: 0.996 - ETA: 0s - loss: 0.0493 - acc: 0.987 - ETA: 0s - loss: 0.0574 - acc: 0.984 - ETA: 0s - loss: 0.0549 - acc: 0.985 - ETA: 0s - loss: 0.0566 - acc: 0.984 - ETA: 0s - loss: 0.0556 - acc: 0.985 - 0s 36us/step - loss: 0.0553 - acc: 0.9859 - val_loss: 0.8725 - val_acc: 0.7703\n",
      "Epoch 86/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0361 - acc: 0.992 - ETA: 0s - loss: 0.0528 - acc: 0.989 - ETA: 0s - loss: 0.0570 - acc: 0.987 - ETA: 0s - loss: 0.0587 - acc: 0.986 - ETA: 0s - loss: 0.0625 - acc: 0.983 - 0s 31us/step - loss: 0.0623 - acc: 0.9835 - val_loss: 0.9314 - val_acc: 0.7752\n",
      "Epoch 87/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0743 - acc: 0.984 - ETA: 0s - loss: 0.0692 - acc: 0.978 - ETA: 0s - loss: 0.0636 - acc: 0.980 - ETA: 0s - loss: 0.0636 - acc: 0.980 - ETA: 0s - loss: 0.0621 - acc: 0.981 - 0s 27us/step - loss: 0.0626 - acc: 0.9809 - val_loss: 0.9178 - val_acc: 0.7683\n",
      "Epoch 88/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0600 - acc: 0.984 - ETA: 0s - loss: 0.0599 - acc: 0.981 - ETA: 0s - loss: 0.0596 - acc: 0.982 - ETA: 0s - loss: 0.0580 - acc: 0.983 - ETA: 0s - loss: 0.0617 - acc: 0.981 - 0s 28us/step - loss: 0.0623 - acc: 0.9816 - val_loss: 0.8897 - val_acc: 0.7713\n",
      "Epoch 89/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0481 - acc: 0.988 - ETA: 0s - loss: 0.0607 - acc: 0.984 - ETA: 0s - loss: 0.0620 - acc: 0.983 - ETA: 0s - loss: 0.0628 - acc: 0.982 - ETA: 0s - loss: 0.0641 - acc: 0.982 - 0s 28us/step - loss: 0.0630 - acc: 0.9821 - val_loss: 0.8858 - val_acc: 0.7654\n",
      "Epoch 90/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.996 - ETA: 0s - loss: 0.0512 - acc: 0.987 - ETA: 0s - loss: 0.0521 - acc: 0.988 - ETA: 0s - loss: 0.0552 - acc: 0.986 - ETA: 0s - loss: 0.0557 - acc: 0.986 - 0s 27us/step - loss: 0.0557 - acc: 0.9861 - val_loss: 0.9178 - val_acc: 0.7664\n",
      "Epoch 91/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0418 - acc: 0.992 - ETA: 0s - loss: 0.0548 - acc: 0.981 - ETA: 0s - loss: 0.0550 - acc: 0.982 - ETA: 0s - loss: 0.0560 - acc: 0.983 - ETA: 0s - loss: 0.0575 - acc: 0.982 - 0s 28us/step - loss: 0.0575 - acc: 0.9825 - val_loss: 0.8778 - val_acc: 0.7732\n",
      "Epoch 92/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0469 - acc: 0.984 - ETA: 0s - loss: 0.0653 - acc: 0.980 - ETA: 0s - loss: 0.0619 - acc: 0.982 - ETA: 0s - loss: 0.0606 - acc: 0.982 - ETA: 0s - loss: 0.0591 - acc: 0.983 - 0s 28us/step - loss: 0.0602 - acc: 0.9828 - val_loss: 0.9218 - val_acc: 0.7693\n",
      "Epoch 93/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0406 - acc: 0.996 - ETA: 0s - loss: 0.0535 - acc: 0.984 - ETA: 0s - loss: 0.0635 - acc: 0.980 - ETA: 0s - loss: 0.0631 - acc: 0.981 - ETA: 0s - loss: 0.0618 - acc: 0.982 - 0s 28us/step - loss: 0.0614 - acc: 0.9829 - val_loss: 0.8945 - val_acc: 0.7742\n",
      "Epoch 94/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0947 - acc: 0.976 - ETA: 0s - loss: 0.0681 - acc: 0.983 - ETA: 0s - loss: 0.0620 - acc: 0.982 - ETA: 0s - loss: 0.0606 - acc: 0.983 - ETA: 0s - loss: 0.0629 - acc: 0.982 - 0s 27us/step - loss: 0.0622 - acc: 0.9828 - val_loss: 0.9047 - val_acc: 0.7615\n",
      "Epoch 95/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0489 - acc: 0.992 - ETA: 0s - loss: 0.0592 - acc: 0.986 - ETA: 0s - loss: 0.0548 - acc: 0.986 - ETA: 0s - loss: 0.0581 - acc: 0.983 - ETA: 0s - loss: 0.0570 - acc: 0.984 - 0s 27us/step - loss: 0.0579 - acc: 0.9838 - val_loss: 0.9270 - val_acc: 0.7732\n",
      "Epoch 96/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0560 - acc: 0.980 - ETA: 0s - loss: 0.0610 - acc: 0.980 - ETA: 0s - loss: 0.0598 - acc: 0.983 - ETA: 0s - loss: 0.0587 - acc: 0.983 - ETA: 0s - loss: 0.0613 - acc: 0.983 - 0s 28us/step - loss: 0.0605 - acc: 0.9835 - val_loss: 0.9199 - val_acc: 0.7654\n",
      "Epoch 97/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0301 - acc: 0.992 - ETA: 0s - loss: 0.0511 - acc: 0.986 - ETA: 0s - loss: 0.0528 - acc: 0.985 - ETA: 0s - loss: 0.0575 - acc: 0.984 - ETA: 0s - loss: 0.0584 - acc: 0.983 - 0s 27us/step - loss: 0.0585 - acc: 0.9834 - val_loss: 0.9288 - val_acc: 0.7556\n",
      "Epoch 98/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0411 - acc: 0.996 - ETA: 0s - loss: 0.0553 - acc: 0.983 - ETA: 0s - loss: 0.0539 - acc: 0.984 - ETA: 0s - loss: 0.0547 - acc: 0.983 - ETA: 0s - loss: 0.0546 - acc: 0.984 - 0s 28us/step - loss: 0.0554 - acc: 0.9839 - val_loss: 0.9386 - val_acc: 0.7566\n",
      "Epoch 99/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0315 - acc: 0.996 - ETA: 0s - loss: 0.0500 - acc: 0.985 - ETA: 0s - loss: 0.0516 - acc: 0.985 - ETA: 0s - loss: 0.0540 - acc: 0.984 - ETA: 0s - loss: 0.0549 - acc: 0.983 - 0s 27us/step - loss: 0.0548 - acc: 0.9835 - val_loss: 0.9062 - val_acc: 0.7683\n",
      "Epoch 100/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 0.0653 - acc: 0.984 - ETA: 0s - loss: 0.0570 - acc: 0.984 - ETA: 0s - loss: 0.0586 - acc: 0.983 - ETA: 0s - loss: 0.0578 - acc: 0.983 - ETA: 0s - loss: 0.0571 - acc: 0.983 - 0s 28us/step - loss: 0.0566 - acc: 0.9837 - val_loss: 0.9418 - val_acc: 0.7605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca4cc9cb00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_based_model.fit(resnet50_features, y_train, batch_size=256, epochs=EPOCHS,  callbacks=callbacks, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
