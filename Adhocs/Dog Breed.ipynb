{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, Input, AveragePooling2D, Lambda\n",
    "from urllib import request\n",
    "from keras.callbacks import TensorBoard\n",
    "import tempfile\n",
    "from keras import optimizers\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from keras.applications import vgg16, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on kaggle kernel: True\n"
     ]
    }
   ],
   "source": [
    "NOT_KAGGLE_KERNEL = os.environ.get('NOT_KAGGLE_KERNEL', 'false') == 'true'\n",
    "print('Run on kaggle kernel:', NOT_KAGGLE_KERNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../input/dog-breed' if NOT_KAGGLE_KERNEL else '../input'\n",
    "EPOCHS = 100\n",
    "IMAGE_SIZE = (224,224)\n",
    "INPUT_SHAPE = IMAGE_SIZE + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        os.makedirs(ROOT_DIR)\n",
    "        zip_path = os.path.join(tempfile.gettempdir(), 'dog-breed.zip')\n",
    "        print('Start download!')\n",
    "        request.urlretrieve('https://kienle.blob.core.windows.net/public/kaggle/dog-breed.zip', zip_path)\n",
    "        print('Start unzip')\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(ROOT_DIR)\n",
    "        with zipfile.ZipFile(os.path.join(ROOT_DIR,'test.zip'), 'r') as zip_ref:\n",
    "            zip_ref.extractall(ROOT_DIR)\n",
    "        with zipfile.ZipFile(os.path.join(ROOT_DIR,'train.zip'), 'r') as zip_ref:\n",
    "            zip_ref.extractall(ROOT_DIR)\n",
    "        os.remove(zip_path)\n",
    "        os.remove(os.path.join(ROOT_DIR,'train.zip'))\n",
    "        os.remove(os.path.join(ROOT_DIR,'test.zip'))\n",
    "        print('Done')\n",
    "if(NOT_KAGGLE_KERNEL):\n",
    "    fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Confirm all data are ready \n",
    "# Expected output: labels.csv  sample_submission.csv  test  train\n",
    "!ls $ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_images = pd.read_csv(os.path.join(ROOT_DIR, 'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10222 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_valid_generator = ImageDataGenerator().flow_from_dataframe(pd_images, os.path.join(ROOT_DIR, 'train'), batch_size=32, x_col='id', y_col='breed', has_ext=False, target_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_valid_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtractor():\n",
    "    def __init__(self, input_shape, pretrained_model, preprocess_input):\n",
    "        self.input_shape = input_shape\n",
    "        model = pretrained_model(include_top=False, input_shape=self.input_shape, weights='imagenet')\n",
    "        inputs = Input(self.input_shape)\n",
    "        x = inputs\n",
    "        x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "        x = model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        model = Model(inputs, x)\n",
    "        self.model = model\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trule\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "vgg_features_extractor = FeaturesExtractor(INPUT_SHAPE, vgg16.VGG16, vgg16.preprocess_input)\n",
    "resnet50_features_extractor = FeaturesExtractor(INPUT_SHAPE, resnet50.ResNet50, resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(num_classes, input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    x = inputs\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 320/320 [00:43<00:00,  7.42it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((train_valid_generator.n,) + INPUT_SHAPE)\n",
    "y_train = np.zeros((train_valid_generator.n, 120))\n",
    "for i in tqdm(range(len(train_valid_generator)), ncols=100):\n",
    "    temp_x, temp_y = train_valid_generator[i]\n",
    "    start_index = i*train_valid_generator.batch_size\n",
    "    X_train[start_index:start_index + temp_x.shape[0]] = temp_x\n",
    "    y_train[start_index:start_index + temp_x.shape[0]] = temp_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate vgg features\n",
    "vgg_features = vgg_features_extractor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 61,560\n",
      "Trainable params: 61,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_based_model = create_simple_model(num_classes, vgg_features_extractor.model.output.get_shape().as_list()[1:])\n",
    "vgg_based_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "if NOT_KAGGLE_KERNEL:\n",
    "    callbacks = [TensorBoard('./data/logs/vgg-{0}'.format(datetime.now().isoformat().replace(':','-')))]\n",
    "else:\n",
    "    callbacks = []\n",
    "    \n",
    "vgg_based_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/100\n",
      "9199/9199 [==============================] - ETA: 14s - loss: 15.1680 - acc: 0.011 - ETA: 1s - loss: 15.0745 - acc: 0.013 - ETA: 0s - loss: 14.9673 - acc: 0.01 - ETA: 0s - loss: 14.8332 - acc: 0.01 - 1s 82us/step - loss: 14.7462 - acc: 0.0208 - val_loss: 12.4536 - val_acc: 0.0655\n",
      "Epoch 2/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 14.1425 - acc: 0.03 - ETA: 0s - loss: 14.1213 - acc: 0.03 - ETA: 0s - loss: 13.9854 - acc: 0.04 - ETA: 0s - loss: 13.8337 - acc: 0.04 - 0s 21us/step - loss: 13.7303 - acc: 0.0498 - val_loss: 10.6226 - val_acc: 0.1476\n",
      "Epoch 3/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 12.7442 - acc: 0.07 - ETA: 0s - loss: 12.7943 - acc: 0.08 - ETA: 0s - loss: 12.4917 - acc: 0.09 - ETA: 0s - loss: 12.3515 - acc: 0.09 - 0s 20us/step - loss: 12.3414 - acc: 0.0994 - val_loss: 8.9972 - val_acc: 0.2317\n",
      "Epoch 4/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 10.5868 - acc: 0.16 - ETA: 0s - loss: 11.3968 - acc: 0.13 - ETA: 0s - loss: 11.2915 - acc: 0.13 - 0s 18us/step - loss: 11.0658 - acc: 0.1444 - val_loss: 7.4488 - val_acc: 0.3050\n",
      "Epoch 5/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 10.1305 - acc: 0.14 - ETA: 0s - loss: 10.0712 - acc: 0.18 - ETA: 0s - loss: 9.9075 - acc: 0.1956 - 0s 18us/step - loss: 9.7790 - acc: 0.2037 - val_loss: 6.5191 - val_acc: 0.3724\n",
      "Epoch 6/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 9.2783 - acc: 0.191 - ETA: 0s - loss: 8.9192 - acc: 0.241 - ETA: 0s - loss: 8.7776 - acc: 0.244 - ETA: 0s - loss: 8.6874 - acc: 0.251 - 0s 19us/step - loss: 8.6782 - acc: 0.2530 - val_loss: 5.7504 - val_acc: 0.4282\n",
      "Epoch 7/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 7.8059 - acc: 0.300 - ETA: 0s - loss: 8.0326 - acc: 0.287 - ETA: 0s - loss: 7.9345 - acc: 0.290 - 0s 18us/step - loss: 7.8251 - acc: 0.2997 - val_loss: 5.2681 - val_acc: 0.4594\n",
      "Epoch 8/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 6.9594 - acc: 0.312 - ETA: 0s - loss: 7.4188 - acc: 0.318 - ETA: 0s - loss: 7.2308 - acc: 0.334 - ETA: 0s - loss: 7.1778 - acc: 0.338 - 0s 19us/step - loss: 7.1663 - acc: 0.3380 - val_loss: 4.7760 - val_acc: 0.4888\n",
      "Epoch 9/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 7.0566 - acc: 0.351 - ETA: 0s - loss: 6.5806 - acc: 0.372 - ETA: 0s - loss: 6.5151 - acc: 0.377 - ETA: 0s - loss: 6.4908 - acc: 0.374 - 0s 20us/step - loss: 6.4881 - acc: 0.3749 - val_loss: 4.3361 - val_acc: 0.4976\n",
      "Epoch 10/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 5.8869 - acc: 0.382 - ETA: 0s - loss: 6.0663 - acc: 0.398 - ETA: 0s - loss: 6.0960 - acc: 0.395 - 0s 18us/step - loss: 6.0509 - acc: 0.3983 - val_loss: 3.9449 - val_acc: 0.5435\n",
      "Epoch 11/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 5.8088 - acc: 0.433 - ETA: 0s - loss: 5.5911 - acc: 0.420 - ETA: 0s - loss: 5.4550 - acc: 0.430 - 0s 18us/step - loss: 5.3847 - acc: 0.4352 - val_loss: 3.7691 - val_acc: 0.5474\n",
      "Epoch 12/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 5.4913 - acc: 0.410 - ETA: 0s - loss: 5.0519 - acc: 0.451 - ETA: 0s - loss: 5.0270 - acc: 0.456 - 0s 18us/step - loss: 5.0860 - acc: 0.4552 - val_loss: 3.6405 - val_acc: 0.5670\n",
      "Epoch 13/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.6190 - acc: 0.449 - ETA: 0s - loss: 4.7545 - acc: 0.488 - ETA: 0s - loss: 4.6745 - acc: 0.494 - 0s 19us/step - loss: 4.7185 - acc: 0.4895 - val_loss: 3.5371 - val_acc: 0.5855\n",
      "Epoch 14/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.2880 - acc: 0.507 - ETA: 0s - loss: 4.4239 - acc: 0.500 - ETA: 0s - loss: 4.4213 - acc: 0.501 - ETA: 0s - loss: 4.4852 - acc: 0.499 - 0s 22us/step - loss: 4.5284 - acc: 0.4976 - val_loss: 3.4936 - val_acc: 0.5787\n",
      "Epoch 15/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.6348 - acc: 0.496 - ETA: 0s - loss: 4.4984 - acc: 0.497 - ETA: 0s - loss: 4.4266 - acc: 0.500 - ETA: 0s - loss: 4.3352 - acc: 0.506 - 0s 19us/step - loss: 4.3287 - acc: 0.5072 - val_loss: 3.3492 - val_acc: 0.5855\n",
      "Epoch 16/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 4.1277 - acc: 0.496 - ETA: 0s - loss: 4.0787 - acc: 0.534 - ETA: 0s - loss: 4.0471 - acc: 0.534 - ETA: 0s - loss: 4.0869 - acc: 0.533 - 0s 20us/step - loss: 4.1074 - acc: 0.5308 - val_loss: 3.3316 - val_acc: 0.5904\n",
      "Epoch 17/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.8763 - acc: 0.554 - ETA: 0s - loss: 3.9169 - acc: 0.552 - ETA: 0s - loss: 3.9732 - acc: 0.545 - ETA: 0s - loss: 3.9379 - acc: 0.544 - 0s 20us/step - loss: 3.9454 - acc: 0.5435 - val_loss: 3.2828 - val_acc: 0.5894\n",
      "Epoch 18/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.6217 - acc: 0.566 - ETA: 0s - loss: 3.8522 - acc: 0.543 - ETA: 0s - loss: 3.8643 - acc: 0.543 - ETA: 0s - loss: 3.8323 - acc: 0.546 - 0s 20us/step - loss: 3.8460 - acc: 0.5459 - val_loss: 3.1813 - val_acc: 0.5924\n",
      "Epoch 19/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.9455 - acc: 0.539 - ETA: 0s - loss: 3.7573 - acc: 0.551 - ETA: 0s - loss: 3.6535 - acc: 0.567 - ETA: 0s - loss: 3.6796 - acc: 0.558 - 0s 22us/step - loss: 3.7192 - acc: 0.5580 - val_loss: 3.1837 - val_acc: 0.6022\n",
      "Epoch 20/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.5344 - acc: 0.605 - ETA: 0s - loss: 3.5955 - acc: 0.570 - ETA: 0s - loss: 3.6066 - acc: 0.570 - ETA: 0s - loss: 3.5646 - acc: 0.572 - 0s 21us/step - loss: 3.5468 - acc: 0.5734 - val_loss: 3.1500 - val_acc: 0.5982\n",
      "Epoch 21/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.5603 - acc: 0.566 - ETA: 0s - loss: 3.4296 - acc: 0.585 - ETA: 0s - loss: 3.4633 - acc: 0.588 - ETA: 0s - loss: 3.4226 - acc: 0.588 - 0s 21us/step - loss: 3.4137 - acc: 0.5883 - val_loss: 3.1935 - val_acc: 0.5953\n",
      "Epoch 22/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.2087 - acc: 0.578 - ETA: 0s - loss: 3.4890 - acc: 0.568 - ETA: 0s - loss: 3.4126 - acc: 0.576 - ETA: 0s - loss: 3.3985 - acc: 0.578 - 0s 22us/step - loss: 3.3733 - acc: 0.5813 - val_loss: 3.1107 - val_acc: 0.6022\n",
      "Epoch 23/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.1071 - acc: 0.644 - ETA: 0s - loss: 3.0545 - acc: 0.603 - ETA: 0s - loss: 3.2101 - acc: 0.596 - ETA: 0s - loss: 3.1880 - acc: 0.597 - 0s 22us/step - loss: 3.2155 - acc: 0.5973 - val_loss: 3.0831 - val_acc: 0.5982\n",
      "Epoch 24/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.0355 - acc: 0.585 - ETA: 0s - loss: 3.0779 - acc: 0.603 - ETA: 0s - loss: 3.1672 - acc: 0.602 - ETA: 0s - loss: 3.1451 - acc: 0.601 - 0s 21us/step - loss: 3.1699 - acc: 0.5997 - val_loss: 3.0182 - val_acc: 0.6158\n",
      "Epoch 25/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.5430 - acc: 0.644 - ETA: 0s - loss: 3.0352 - acc: 0.614 - ETA: 0s - loss: 3.0320 - acc: 0.611 - ETA: 0s - loss: 3.0739 - acc: 0.608 - 0s 20us/step - loss: 3.0702 - acc: 0.6076 - val_loss: 2.9032 - val_acc: 0.6158\n",
      "Epoch 26/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.0370 - acc: 0.566 - ETA: 0s - loss: 2.8476 - acc: 0.620 - ETA: 0s - loss: 2.9825 - acc: 0.608 - ETA: 0s - loss: 2.9754 - acc: 0.611 - 0s 19us/step - loss: 2.9821 - acc: 0.6110 - val_loss: 2.9594 - val_acc: 0.6149\n",
      "Epoch 27/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.0692 - acc: 0.601 - ETA: 0s - loss: 3.0082 - acc: 0.612 - ETA: 0s - loss: 2.9783 - acc: 0.615 - 0s 18us/step - loss: 2.9590 - acc: 0.6179 - val_loss: 2.8974 - val_acc: 0.6266\n",
      "Epoch 28/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.7581 - acc: 0.636 - ETA: 0s - loss: 2.8235 - acc: 0.630 - ETA: 0s - loss: 2.8323 - acc: 0.621 - 0s 18us/step - loss: 2.8840 - acc: 0.6157 - val_loss: 2.8493 - val_acc: 0.6237\n",
      "Epoch 29/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.6137 - acc: 0.652 - ETA: 0s - loss: 2.8212 - acc: 0.627 - ETA: 0s - loss: 2.8023 - acc: 0.628 - 0s 18us/step - loss: 2.7480 - acc: 0.6331 - val_loss: 2.7678 - val_acc: 0.6207\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - ETA: 0s - loss: 2.6980 - acc: 0.652 - ETA: 0s - loss: 2.7642 - acc: 0.631 - ETA: 0s - loss: 2.7082 - acc: 0.633 - ETA: 0s - loss: 2.7267 - acc: 0.635 - 0s 19us/step - loss: 2.7273 - acc: 0.6346 - val_loss: 2.8446 - val_acc: 0.6022\n",
      "Epoch 31/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2740 - acc: 0.664 - ETA: 0s - loss: 2.6458 - acc: 0.629 - ETA: 0s - loss: 2.6227 - acc: 0.635 - 0s 18us/step - loss: 2.6836 - acc: 0.6340 - val_loss: 2.7049 - val_acc: 0.6364\n",
      "Epoch 32/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3172 - acc: 0.691 - ETA: 0s - loss: 2.6288 - acc: 0.639 - ETA: 0s - loss: 2.6561 - acc: 0.636 - 0s 17us/step - loss: 2.6814 - acc: 0.6377 - val_loss: 2.7499 - val_acc: 0.6266\n",
      "Epoch 33/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.5859 - acc: 0.664 - ETA: 0s - loss: 2.7324 - acc: 0.633 - ETA: 0s - loss: 2.5601 - acc: 0.649 - ETA: 0s - loss: 2.5749 - acc: 0.647 - 0s 24us/step - loss: 2.6472 - acc: 0.6385 - val_loss: 2.7748 - val_acc: 0.6237\n",
      "Epoch 34/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.5298 - acc: 0.632 - ETA: 0s - loss: 2.4952 - acc: 0.657 - ETA: 0s - loss: 2.5651 - acc: 0.646 - ETA: 0s - loss: 2.5746 - acc: 0.647 - 0s 24us/step - loss: 2.5593 - acc: 0.6475 - val_loss: 2.7249 - val_acc: 0.6276\n",
      "Epoch 35/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 3.3788 - acc: 0.585 - ETA: 0s - loss: 2.5397 - acc: 0.642 - ETA: 0s - loss: 2.5759 - acc: 0.643 - ETA: 0s - loss: 2.5805 - acc: 0.642 - 0s 20us/step - loss: 2.5988 - acc: 0.6399 - val_loss: 2.6898 - val_acc: 0.6285\n",
      "Epoch 36/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3073 - acc: 0.675 - ETA: 0s - loss: 2.4689 - acc: 0.653 - ETA: 0s - loss: 2.4420 - acc: 0.658 - ETA: 0s - loss: 2.4468 - acc: 0.658 - 0s 22us/step - loss: 2.4723 - acc: 0.6552 - val_loss: 2.7275 - val_acc: 0.6227\n",
      "Epoch 37/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.4436 - acc: 0.699 - ETA: 0s - loss: 2.3956 - acc: 0.656 - ETA: 0s - loss: 2.4672 - acc: 0.645 - ETA: 0s - loss: 2.4471 - acc: 0.652 - 0s 21us/step - loss: 2.4840 - acc: 0.6491 - val_loss: 2.6998 - val_acc: 0.6276\n",
      "Epoch 38/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0121 - acc: 0.691 - ETA: 0s - loss: 2.5020 - acc: 0.649 - ETA: 0s - loss: 2.4117 - acc: 0.657 - 0s 18us/step - loss: 2.4263 - acc: 0.6604 - val_loss: 2.7121 - val_acc: 0.6207\n",
      "Epoch 39/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1592 - acc: 0.718 - ETA: 0s - loss: 2.3357 - acc: 0.666 - ETA: 0s - loss: 2.3684 - acc: 0.669 - ETA: 0s - loss: 2.4264 - acc: 0.662 - 0s 21us/step - loss: 2.4427 - acc: 0.6613 - val_loss: 2.7011 - val_acc: 0.6276\n",
      "Epoch 40/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2315 - acc: 0.687 - ETA: 0s - loss: 2.3904 - acc: 0.665 - ETA: 0s - loss: 2.4157 - acc: 0.656 - ETA: 0s - loss: 2.4190 - acc: 0.657 - 0s 21us/step - loss: 2.4225 - acc: 0.6579 - val_loss: 2.6775 - val_acc: 0.6285\n",
      "Epoch 41/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5784 - acc: 0.718 - ETA: 0s - loss: 2.3196 - acc: 0.668 - ETA: 0s - loss: 2.3609 - acc: 0.661 - 0s 18us/step - loss: 2.3985 - acc: 0.6611 - val_loss: 2.6785 - val_acc: 0.6442\n",
      "Epoch 42/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.9152 - acc: 0.589 - ETA: 0s - loss: 2.4686 - acc: 0.641 - ETA: 0s - loss: 2.3732 - acc: 0.652 - ETA: 0s - loss: 2.3866 - acc: 0.653 - 0s 19us/step - loss: 2.3973 - acc: 0.6531 - val_loss: 2.7254 - val_acc: 0.6237\n",
      "Epoch 43/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3234 - acc: 0.664 - ETA: 0s - loss: 2.4246 - acc: 0.662 - ETA: 0s - loss: 2.3391 - acc: 0.670 - 0s 18us/step - loss: 2.3814 - acc: 0.6654 - val_loss: 2.6738 - val_acc: 0.6266\n",
      "Epoch 44/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3369 - acc: 0.668 - ETA: 0s - loss: 2.3928 - acc: 0.660 - ETA: 0s - loss: 2.3415 - acc: 0.659 - ETA: 0s - loss: 2.3159 - acc: 0.661 - 0s 19us/step - loss: 2.3156 - acc: 0.6621 - val_loss: 2.5777 - val_acc: 0.6217\n",
      "Epoch 45/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2726 - acc: 0.660 - ETA: 0s - loss: 2.1826 - acc: 0.677 - ETA: 0s - loss: 2.2510 - acc: 0.663 - ETA: 0s - loss: 2.2602 - acc: 0.663 - 0s 19us/step - loss: 2.2734 - acc: 0.6624 - val_loss: 2.6032 - val_acc: 0.6354\n",
      "Epoch 46/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2933 - acc: 0.671 - ETA: 0s - loss: 2.3343 - acc: 0.662 - ETA: 0s - loss: 2.2613 - acc: 0.666 - ETA: 0s - loss: 2.2545 - acc: 0.669 - 0s 19us/step - loss: 2.2641 - acc: 0.6684 - val_loss: 2.5937 - val_acc: 0.6334\n",
      "Epoch 47/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3669 - acc: 0.656 - ETA: 0s - loss: 2.1818 - acc: 0.669 - ETA: 0s - loss: 2.2588 - acc: 0.661 - 0s 18us/step - loss: 2.2496 - acc: 0.6663 - val_loss: 2.5929 - val_acc: 0.6315\n",
      "Epoch 48/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1064 - acc: 0.687 - ETA: 0s - loss: 2.1753 - acc: 0.674 - ETA: 0s - loss: 2.1945 - acc: 0.681 - 0s 18us/step - loss: 2.1777 - acc: 0.6776 - val_loss: 2.6007 - val_acc: 0.6334\n",
      "Epoch 49/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9234 - acc: 0.707 - ETA: 0s - loss: 2.2466 - acc: 0.668 - ETA: 0s - loss: 2.2319 - acc: 0.669 - 0s 18us/step - loss: 2.2258 - acc: 0.6684 - val_loss: 2.5578 - val_acc: 0.6227\n",
      "Epoch 50/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7481 - acc: 0.734 - ETA: 0s - loss: 2.0502 - acc: 0.686 - ETA: 0s - loss: 2.1498 - acc: 0.673 - ETA: 0s - loss: 2.1702 - acc: 0.670 - 0s 19us/step - loss: 2.1658 - acc: 0.6712 - val_loss: 2.5458 - val_acc: 0.6325\n",
      "Epoch 51/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1857 - acc: 0.664 - ETA: 0s - loss: 2.0657 - acc: 0.677 - ETA: 0s - loss: 2.1305 - acc: 0.674 - ETA: 0s - loss: 2.1458 - acc: 0.672 - 0s 19us/step - loss: 2.1389 - acc: 0.6729 - val_loss: 2.5233 - val_acc: 0.6276\n",
      "Epoch 52/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6954 - acc: 0.718 - ETA: 0s - loss: 2.2225 - acc: 0.668 - ETA: 0s - loss: 2.1628 - acc: 0.676 - ETA: 0s - loss: 2.1605 - acc: 0.671 - 0s 19us/step - loss: 2.1611 - acc: 0.6715 - val_loss: 2.4683 - val_acc: 0.6413\n",
      "Epoch 53/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.6602 - acc: 0.648 - ETA: 0s - loss: 2.1112 - acc: 0.676 - ETA: 0s - loss: 2.1459 - acc: 0.675 - ETA: 0s - loss: 2.1120 - acc: 0.679 - 0s 19us/step - loss: 2.1030 - acc: 0.6809 - val_loss: 2.5129 - val_acc: 0.6315\n",
      "Epoch 54/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7694 - acc: 0.734 - ETA: 0s - loss: 2.1091 - acc: 0.688 - ETA: 0s - loss: 2.0817 - acc: 0.688 - ETA: 0s - loss: 2.1319 - acc: 0.679 - 0s 19us/step - loss: 2.1305 - acc: 0.6794 - val_loss: 2.4733 - val_acc: 0.6383\n",
      "Epoch 55/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2881 - acc: 0.664 - ETA: 0s - loss: 2.1237 - acc: 0.676 - ETA: 0s - loss: 2.1049 - acc: 0.677 - ETA: 0s - loss: 2.0827 - acc: 0.679 - 0s 19us/step - loss: 2.0970 - acc: 0.6769 - val_loss: 2.4550 - val_acc: 0.6393\n",
      "Epoch 56/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.4843 - acc: 0.668 - ETA: 0s - loss: 2.0447 - acc: 0.684 - ETA: 0s - loss: 2.0709 - acc: 0.677 - 0s 18us/step - loss: 2.0940 - acc: 0.6765 - val_loss: 2.5220 - val_acc: 0.6422\n",
      "Epoch 57/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3603 - acc: 0.644 - ETA: 0s - loss: 2.0708 - acc: 0.685 - ETA: 0s - loss: 2.0500 - acc: 0.685 - 0s 18us/step - loss: 2.0667 - acc: 0.6840 - val_loss: 2.4595 - val_acc: 0.6315\n",
      "Epoch 58/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0742 - acc: 0.675 - ETA: 0s - loss: 2.0627 - acc: 0.681 - ETA: 0s - loss: 2.0905 - acc: 0.682 - 0s 18us/step - loss: 2.0848 - acc: 0.6796 - val_loss: 2.4888 - val_acc: 0.6403\n",
      "Epoch 59/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3718 - acc: 0.632 - ETA: 0s - loss: 2.1053 - acc: 0.668 - ETA: 0s - loss: 2.0772 - acc: 0.672 - 0s 18us/step - loss: 2.0633 - acc: 0.6738 - val_loss: 2.4344 - val_acc: 0.6422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0693 - acc: 0.718 - ETA: 0s - loss: 2.0286 - acc: 0.686 - ETA: 0s - loss: 1.9939 - acc: 0.682 - ETA: 0s - loss: 2.0304 - acc: 0.679 - 0s 20us/step - loss: 2.0396 - acc: 0.6787 - val_loss: 2.4781 - val_acc: 0.6305\n",
      "Epoch 61/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8783 - acc: 0.668 - ETA: 0s - loss: 2.0478 - acc: 0.689 - ETA: 0s - loss: 2.0504 - acc: 0.686 - 0s 18us/step - loss: 2.0456 - acc: 0.6834 - val_loss: 2.4824 - val_acc: 0.6383\n",
      "Epoch 62/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1971 - acc: 0.722 - ETA: 0s - loss: 1.9834 - acc: 0.703 - ETA: 0s - loss: 2.0220 - acc: 0.691 - 0s 18us/step - loss: 2.0396 - acc: 0.6874 - val_loss: 2.4781 - val_acc: 0.6325\n",
      "Epoch 63/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.0520 - acc: 0.691 - ETA: 0s - loss: 1.9874 - acc: 0.685 - ETA: 0s - loss: 2.0215 - acc: 0.685 - ETA: 0s - loss: 2.0154 - acc: 0.683 - 0s 19us/step - loss: 2.0092 - acc: 0.6838 - val_loss: 2.4588 - val_acc: 0.6373\n",
      "Epoch 64/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8674 - acc: 0.652 - ETA: 0s - loss: 1.9442 - acc: 0.682 - ETA: 0s - loss: 1.9992 - acc: 0.675 - 0s 18us/step - loss: 2.0443 - acc: 0.6739 - val_loss: 2.4799 - val_acc: 0.6276\n",
      "Epoch 65/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9324 - acc: 0.644 - ETA: 0s - loss: 1.9387 - acc: 0.691 - ETA: 0s - loss: 1.9562 - acc: 0.690 - 0s 18us/step - loss: 2.0086 - acc: 0.6851 - val_loss: 2.4461 - val_acc: 0.6256\n",
      "Epoch 66/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.1368 - acc: 0.636 - ETA: 0s - loss: 1.9433 - acc: 0.687 - ETA: 0s - loss: 1.9818 - acc: 0.690 - ETA: 0s - loss: 2.0086 - acc: 0.685 - 0s 20us/step - loss: 1.9873 - acc: 0.6874 - val_loss: 2.4539 - val_acc: 0.6354\n",
      "Epoch 67/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6586 - acc: 0.703 - ETA: 0s - loss: 2.0095 - acc: 0.674 - ETA: 0s - loss: 2.0645 - acc: 0.670 - 0s 18us/step - loss: 2.0474 - acc: 0.6743 - val_loss: 2.4837 - val_acc: 0.6197\n",
      "Epoch 68/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7635 - acc: 0.691 - ETA: 0s - loss: 1.9007 - acc: 0.691 - ETA: 0s - loss: 1.9136 - acc: 0.695 - 0s 18us/step - loss: 1.9593 - acc: 0.6869 - val_loss: 2.3389 - val_acc: 0.6383\n",
      "Epoch 69/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7474 - acc: 0.687 - ETA: 0s - loss: 1.9429 - acc: 0.698 - ETA: 0s - loss: 1.9497 - acc: 0.687 - 0s 18us/step - loss: 1.9469 - acc: 0.6852 - val_loss: 2.2794 - val_acc: 0.6364\n",
      "Epoch 70/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7709 - acc: 0.699 - ETA: 0s - loss: 1.8769 - acc: 0.696 - ETA: 0s - loss: 1.9467 - acc: 0.690 - 0s 18us/step - loss: 1.9627 - acc: 0.6857 - val_loss: 2.3491 - val_acc: 0.6364\n",
      "Epoch 71/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8693 - acc: 0.695 - ETA: 0s - loss: 1.9889 - acc: 0.685 - ETA: 0s - loss: 1.9449 - acc: 0.687 - 0s 18us/step - loss: 1.9423 - acc: 0.6853 - val_loss: 2.3086 - val_acc: 0.6471\n",
      "Epoch 72/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8620 - acc: 0.718 - ETA: 0s - loss: 1.9236 - acc: 0.681 - ETA: 0s - loss: 1.9177 - acc: 0.682 - ETA: 0s - loss: 1.9274 - acc: 0.683 - 0s 19us/step - loss: 1.9290 - acc: 0.6841 - val_loss: 2.3698 - val_acc: 0.6364\n",
      "Epoch 73/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7266 - acc: 0.687 - ETA: 0s - loss: 1.8222 - acc: 0.699 - ETA: 0s - loss: 1.8383 - acc: 0.694 - 0s 18us/step - loss: 1.8896 - acc: 0.6912 - val_loss: 2.3447 - val_acc: 0.6325\n",
      "Epoch 74/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8404 - acc: 0.710 - ETA: 0s - loss: 1.9273 - acc: 0.685 - ETA: 0s - loss: 1.9001 - acc: 0.694 - 0s 18us/step - loss: 1.9009 - acc: 0.6900 - val_loss: 2.3405 - val_acc: 0.6403\n",
      "Epoch 75/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7961 - acc: 0.699 - ETA: 0s - loss: 1.9002 - acc: 0.690 - ETA: 0s - loss: 1.9076 - acc: 0.691 - 0s 18us/step - loss: 1.9179 - acc: 0.6896 - val_loss: 2.2809 - val_acc: 0.6344\n",
      "Epoch 76/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8968 - acc: 0.683 - ETA: 0s - loss: 1.8885 - acc: 0.695 - ETA: 0s - loss: 1.8984 - acc: 0.692 - 0s 18us/step - loss: 1.9066 - acc: 0.6867 - val_loss: 2.2952 - val_acc: 0.6452\n",
      "Epoch 77/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6052 - acc: 0.730 - ETA: 0s - loss: 1.8471 - acc: 0.697 - ETA: 0s - loss: 1.8625 - acc: 0.694 - ETA: 0s - loss: 1.8639 - acc: 0.694 - 0s 19us/step - loss: 1.8787 - acc: 0.6936 - val_loss: 2.3121 - val_acc: 0.6393\n",
      "Epoch 78/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6099 - acc: 0.726 - ETA: 0s - loss: 1.8093 - acc: 0.695 - ETA: 0s - loss: 1.9068 - acc: 0.693 - ETA: 0s - loss: 1.9398 - acc: 0.688 - 0s 19us/step - loss: 1.9214 - acc: 0.6891 - val_loss: 2.2511 - val_acc: 0.6491\n",
      "Epoch 79/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.3672 - acc: 0.668 - ETA: 0s - loss: 1.9569 - acc: 0.686 - ETA: 0s - loss: 1.8573 - acc: 0.695 - 0s 18us/step - loss: 1.9057 - acc: 0.6928 - val_loss: 2.2408 - val_acc: 0.6432\n",
      "Epoch 80/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6026 - acc: 0.660 - ETA: 0s - loss: 1.8868 - acc: 0.694 - ETA: 0s - loss: 1.8971 - acc: 0.686 - 0s 18us/step - loss: 1.9110 - acc: 0.6886 - val_loss: 2.3003 - val_acc: 0.6520\n",
      "Epoch 81/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9526 - acc: 0.687 - ETA: 0s - loss: 1.7675 - acc: 0.697 - ETA: 0s - loss: 1.7960 - acc: 0.695 - 0s 18us/step - loss: 1.8579 - acc: 0.6901 - val_loss: 2.3039 - val_acc: 0.6354\n",
      "Epoch 82/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 2.2053 - acc: 0.675 - ETA: 0s - loss: 1.9242 - acc: 0.685 - ETA: 0s - loss: 1.8999 - acc: 0.686 - 0s 17us/step - loss: 1.9142 - acc: 0.6845 - val_loss: 2.3076 - val_acc: 0.6471\n",
      "Epoch 83/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6148 - acc: 0.707 - ETA: 0s - loss: 1.7421 - acc: 0.711 - ETA: 0s - loss: 1.8198 - acc: 0.702 - ETA: 0s - loss: 1.8678 - acc: 0.693 - 0s 19us/step - loss: 1.8566 - acc: 0.6946 - val_loss: 2.3056 - val_acc: 0.6315\n",
      "Epoch 84/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.3082 - acc: 0.746 - ETA: 0s - loss: 1.8360 - acc: 0.701 - ETA: 0s - loss: 1.8600 - acc: 0.694 - ETA: 0s - loss: 1.8914 - acc: 0.690 - 0s 19us/step - loss: 1.8879 - acc: 0.6889 - val_loss: 2.2153 - val_acc: 0.6373\n",
      "Epoch 85/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.4906 - acc: 0.718 - ETA: 0s - loss: 1.7787 - acc: 0.696 - ETA: 0s - loss: 1.7873 - acc: 0.696 - 0s 18us/step - loss: 1.7982 - acc: 0.6922 - val_loss: 2.2040 - val_acc: 0.6315\n",
      "Epoch 86/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5483 - acc: 0.707 - ETA: 0s - loss: 1.7560 - acc: 0.693 - ETA: 0s - loss: 1.7361 - acc: 0.695 - 0s 18us/step - loss: 1.7896 - acc: 0.6894 - val_loss: 2.2179 - val_acc: 0.6422\n",
      "Epoch 87/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.2356 - acc: 0.753 - ETA: 0s - loss: 1.7056 - acc: 0.695 - ETA: 0s - loss: 1.7255 - acc: 0.691 - 0s 18us/step - loss: 1.7538 - acc: 0.6895 - val_loss: 2.2069 - val_acc: 0.6413\n",
      "Epoch 88/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.8574 - acc: 0.691 - ETA: 0s - loss: 1.7500 - acc: 0.693 - ETA: 0s - loss: 1.7503 - acc: 0.695 - ETA: 0s - loss: 1.7544 - acc: 0.694 - 0s 19us/step - loss: 1.7569 - acc: 0.6938 - val_loss: 2.1606 - val_acc: 0.6559\n",
      "Epoch 89/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7732 - acc: 0.746 - ETA: 0s - loss: 1.8498 - acc: 0.695 - ETA: 0s - loss: 1.7511 - acc: 0.701 - 0s 18us/step - loss: 1.7609 - acc: 0.6962 - val_loss: 2.1638 - val_acc: 0.6413\n",
      "Epoch 90/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7439 - acc: 0.703 - ETA: 0s - loss: 1.7486 - acc: 0.706 - ETA: 0s - loss: 1.7263 - acc: 0.700 - ETA: 0s - loss: 1.7414 - acc: 0.696 - 0s 20us/step - loss: 1.7383 - acc: 0.6943 - val_loss: 2.1581 - val_acc: 0.6432\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5459 - acc: 0.738 - ETA: 0s - loss: 1.6610 - acc: 0.708 - ETA: 0s - loss: 1.6603 - acc: 0.704 - 0s 18us/step - loss: 1.7084 - acc: 0.7016 - val_loss: 2.1520 - val_acc: 0.6520\n",
      "Epoch 92/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.9458 - acc: 0.703 - ETA: 0s - loss: 1.7164 - acc: 0.699 - ETA: 0s - loss: 1.7420 - acc: 0.699 - 0s 18us/step - loss: 1.7206 - acc: 0.6984 - val_loss: 2.1641 - val_acc: 0.6569\n",
      "Epoch 93/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5598 - acc: 0.750 - ETA: 0s - loss: 1.6624 - acc: 0.717 - ETA: 0s - loss: 1.6967 - acc: 0.710 - 0s 18us/step - loss: 1.6991 - acc: 0.7084 - val_loss: 2.1809 - val_acc: 0.6500\n",
      "Epoch 94/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5986 - acc: 0.726 - ETA: 0s - loss: 1.6170 - acc: 0.721 - ETA: 0s - loss: 1.6839 - acc: 0.709 - 0s 18us/step - loss: 1.7164 - acc: 0.7051 - val_loss: 2.2461 - val_acc: 0.6422\n",
      "Epoch 95/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5431 - acc: 0.730 - ETA: 0s - loss: 1.6846 - acc: 0.702 - ETA: 0s - loss: 1.7001 - acc: 0.700 - 0s 17us/step - loss: 1.7058 - acc: 0.6971 - val_loss: 2.2073 - val_acc: 0.6403\n",
      "Epoch 96/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.7530 - acc: 0.668 - ETA: 0s - loss: 1.8321 - acc: 0.694 - ETA: 0s - loss: 1.6946 - acc: 0.700 - 0s 18us/step - loss: 1.7169 - acc: 0.6962 - val_loss: 2.1569 - val_acc: 0.6442\n",
      "Epoch 97/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6579 - acc: 0.703 - ETA: 0s - loss: 1.7166 - acc: 0.688 - ETA: 0s - loss: 1.7464 - acc: 0.690 - 0s 17us/step - loss: 1.7250 - acc: 0.6916 - val_loss: 2.1635 - val_acc: 0.6403\n",
      "Epoch 98/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.6947 - acc: 0.691 - ETA: 0s - loss: 1.6971 - acc: 0.697 - ETA: 0s - loss: 1.7122 - acc: 0.696 - 0s 18us/step - loss: 1.7225 - acc: 0.6952 - val_loss: 2.1690 - val_acc: 0.6471\n",
      "Epoch 99/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.5640 - acc: 0.726 - ETA: 0s - loss: 1.6948 - acc: 0.710 - ETA: 0s - loss: 1.7021 - acc: 0.705 - 0s 18us/step - loss: 1.6985 - acc: 0.7044 - val_loss: 2.1574 - val_acc: 0.6588\n",
      "Epoch 100/100\n",
      "9199/9199 [==============================] - ETA: 0s - loss: 1.4320 - acc: 0.730 - ETA: 0s - loss: 1.6668 - acc: 0.699 - ETA: 0s - loss: 1.6905 - acc: 0.701 - 0s 18us/step - loss: 1.7253 - acc: 0.6993 - val_loss: 2.1788 - val_acc: 0.6481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c72e3f2ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_based_model.fit(vgg_features, y_train, batch_size=256, epochs=EPOCHS, callbacks=callbacks, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_features = resnet50_features_extractor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_based_model = create_simple_model(num_classes, resnet50_features_extractor.model.output.get_shape().as_list()[1:])\n",
    "resnet50_based_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "if NOT_KAGGLE_KERNEL:\n",
    "    callbacks = [TensorBoard('./data/logs/resnet50-{0}'.format(datetime.now().isoformat().replace(':','-')))]\n",
    "else:\n",
    "    callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n"
     ]
    }
   ],
   "source": [
    "resnet50_based_model.fit(resnet50_features, y_train, batch_size=256, epochs=EPOCHS,  callbacks=callbacks, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
